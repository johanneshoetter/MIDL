{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Intelligence with Deep Learning\n",
    "## Importance batching for improved training of neural networks\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import ResNet18\n",
    "from utils.data_utils import DataLoader\n",
    "from utils.logging_utils import *\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "today = datetime.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEEDS = [10, 42, 4] # don't change!\n",
    "#STRATEGIES = ['freeze', 'shuffle', 'homogeneous', 'heterogeneous'] # can be changed\n",
    "SEEDS = [10]\n",
    "STRATEGIES = ['max_k_loss', 'min_k_loss', 'shuffle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training\n",
    "def train(epoch, optimizer, criterion_fn, seed, dataloader, strategy, device, num_iterations):\n",
    "    criterion = criterion_fn()\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader.yield_batches(strategy, \\\n",
    "                                                  random_state=seed, use_train=True, \\\n",
    "                                                  criterion=criterion_fn(reduction='none'),\\\n",
    "                                                  device=device, num_iterations=num_iterations)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    train_acc = 100.*correct/total\n",
    "    train_loss /= total\n",
    "    return train_acc, train_loss\n",
    "\n",
    "### Testing\n",
    "def test(epoch, best_acc, criterion_fn, seed, dataloader):\n",
    "    criterion = criterion_fn()\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader.yield_batches('shuffle', \\\n",
    "                                                                               random_state=seed, use_train=False)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    test_acc = 100.*correct/total\n",
    "    test_loss /= total\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        net.save(best_acc, epoch, seed, strategy)\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| Seeds: [10]                                                                            |\n",
      "| Strategies: ['max_k_loss', 'min_k_loss', 'shuffle']                                    |\n",
      "| -> Resulting number of iterations: 3                                                   |\n",
      "| Number of iterations: 2                                                                |\n",
      "| Learning rates: {'1': 0.1, '50': 0.01, '90': 0.005, '120': 0.001}                      |\n",
      "| Resuming from checkpoint: False                                                        |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| Seed: 10      Strategy: max_k_loss                                                         |\n",
      "| Epoch         Train Accuracy  Test Accuracy   Train Loss   Test Loss                   |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "NUMBER OF ITERATIONS:  5\n",
      "| [1/2]:    26.25           010.0           0.12092      8285.88141                     |\n",
      "NUMBER OF ITERATIONS:  5\n",
      "| [2/2]:    000.0           10.37           0.27041      8.33711                     |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| Seed: 10      Strategy: min_k_loss                                                         |\n",
      "| Epoch         Train Accuracy  Test Accuracy   Train Loss   Test Loss                   |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| [1/2]:    100.0           010.0           00.0043      1662.5758                     |\n",
      "| [2/2]:    100.0           010.0           00000.0      117.24165                     |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| Seed: 10      Strategy: shuffle                                                         |\n",
      "| Epoch         Train Accuracy  Test Accuracy   Train Loss   Test Loss                   |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| [1/2]:    31.06           041.1           0.02987      0.02603                     |\n",
      "| [2/2]:    48.51           48.96           0.02205      0.02266                     |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "\n",
      "Finished training. Time needed: 0 hrs 3 mins 38 secs\n"
     ]
    }
   ],
   "source": [
    "resume = False\n",
    "given_date = '20191113' #only needed if resumed from checkpoint\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "### task: classification of the following classes\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    \n",
    "### hyperparameters\n",
    "test_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "num_epochs = 2 # number of iterations the model gets trained\n",
    "learning_rates = { # learning rate is reset after specific epochs\n",
    "    '1': 0.1, # 50 epochs\n",
    "    '50': 0.01, # 40 epochs\n",
    "    '90': 0.005, # 30 epochs\n",
    "    '120': 0.001 # 30 epochs\n",
    "}\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "num_iterations = {\n",
    "    'max_k_loss': 5,\n",
    "    'min_k_loss': 5\n",
    "}\n",
    "\n",
    "print(\"Begin training.\")\n",
    "start = timeit.default_timer()\n",
    "#Logging header\n",
    "length_table = 90\n",
    "log_separating_line(length_table)\n",
    "log_header_line(\"Seeds: {}\".format(SEEDS), length_table)\n",
    "log_header_line(\"Strategies: {}\".format(STRATEGIES), length_table)\n",
    "log_header_line(\"-> Resulting number of iterations: {}\".format(len(SEEDS) * len(STRATEGIES)), length_table)\n",
    "log_header_line(\"Number of iterations: {}\".format(num_epochs), length_table)\n",
    "log_header_line(\"Learning rates: {}\".format(learning_rates), length_table)\n",
    "log_header_line(\"Resuming from checkpoint: {}\".format(True if resume else False), length_table)\n",
    "log_separating_line(length_table)\n",
    "\n",
    "rows = []\n",
    "for seed in SEEDS:\n",
    "    for strategy in STRATEGIES:\n",
    "                \n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "             \n",
    "        ### Model\n",
    "        net = ResNet18()\n",
    "        net = net.to(device)\n",
    "        criterion = nn.CrossEntropyLoss # no function!\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rates['1'], momentum=momentum, weight_decay=weight_decay)\n",
    "        \n",
    "        ### load the data\n",
    "        # if needed, specify batch sizes and shuffle settings\n",
    "        dataloader = DataLoader()\n",
    "        dataloader.download_cifar()\n",
    "        dataloader.set_model(net)\n",
    "        print()\n",
    "        log_separating_line(length_table)\n",
    "        log_position_header(seed, strategy, length_table)\n",
    "        log_separating_line(length_table)\n",
    "\n",
    "        if resume:\n",
    "            assert os.path.isdir('serialized'), 'Error: no serialized directory found!'\n",
    "            ckpt = torch.load('./serialized/{}/{}_ckpt_{}.pth'.format(given_date, strategy, seed))\n",
    "            test_acc, start_epoch, net = net.load(ckpt)\n",
    "\n",
    "        for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "            # reset learning rate at specific epochs\n",
    "            if str(epoch+1) in learning_rates.keys():\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = learning_rates[str(epoch+1)]\n",
    "                    \n",
    "            train_acc, train_loss = train(epoch, optimizer, criterion, seed, dataloader, \\\n",
    "                                          strategy, device, num_iterations.get(strategy))\n",
    "            test_acc, test_loss = test(epoch, test_acc, criterion, seed, dataloader)\n",
    "            log_position_line(epoch + 1, num_epochs, train_acc, test_acc, train_loss, test_loss, length_table)\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'seed': seed,\n",
    "                'train': True,\n",
    "                'strategy': strategy,\n",
    "                'accuracy': train_acc,\n",
    "                'loss': train_loss\n",
    "            }\n",
    "            rows.append(row)\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'seed': seed,\n",
    "                'train': False,\n",
    "                'strategy': strategy,\n",
    "                'accuracy': test_acc,\n",
    "                'loss': test_loss\n",
    "            }\n",
    "            rows.append(row)\n",
    "        log_separating_line(length_table)\n",
    "            \n",
    "stop = timeit.default_timer()\n",
    "time_needed = stop - start\n",
    "hrs = int(time_needed / 3600)\n",
    "mins = int((time_needed / 60) % 60)\n",
    "secs = int(time_needed % 60)\n",
    "print()\n",
    "print(\"Finished training. Time needed: {} hrs {} mins {} secs\".format(hrs, mins, secs))\n",
    "\n",
    "logging_df = pd.DataFrame(rows, columns=['epoch', 'seed', 'train', 'strategy', 'accuracy', 'loss'])   \n",
    "training_logs_dir = 'evaluation_logs'\n",
    "logging_df.to_csv('{}.txt'.format(os.path.join(training_logs_dir, today)), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
