{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Intelligence with Deep Learning\n",
    "## Importance batching for improved training of neural networks\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import ResNet18\n",
    "from utils.data_utils import DataLoader\n",
    "from utils.logging_utils import *\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "today = datetime.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [10, 42, 4] # don't change!\n",
    "#STRATEGIES = ['freeze', 'shuffle', 'homogeneous', 'heterogeneous', 'max_k_loss', 'min_k_loss'] # can be changed\n",
    "STRATEGIES = ['max_k_loss']\n",
    "#['weighted_random_sampling']#, 'max_k_loss']#, 'heterogeneous_max_k_loss', 'heterogeneous_min_k_loss']\n",
    "UPDATE_STRATEGIES = ['on_test_acc_reduction', 'every_epoch', 'every_iteration']\n",
    "update_strategy = UPDATE_STRATEGIES[0] # current implementation: choose one during testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training\n",
    "def train(epoch, optimizer, criterion_fn, seed, dataloader, strategy, device, update_strategy):\n",
    "    criterion = criterion_fn()\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    update_every_iteration = True if update_strategy == 'every_iteration' else False\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader.yield_batches(strategy, \\\n",
    "                                                  random_state=seed, use_train=True, \\\n",
    "                                                  criterion=criterion_fn(reduction='none'),\\\n",
    "                                                  device=device, num_iterations=500,\n",
    "                                                  update_every_iteration=update_every_iteration)): # 500: 50,000 images / 100 batch size\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader.yield_batches('freeze', \\\n",
    "                                                                               random_state=seed, use_train=True)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    train_acc = 100.*correct/total\n",
    "    train_loss /= total\n",
    "    return train_acc, train_loss\n",
    "\n",
    "### Testing\n",
    "def test(epoch, best_acc, criterion_fn, seed, dataloader, strategy, device, last_acc, update_strategy):\n",
    "    criterion = criterion_fn()\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader.yield_batches('freeze', \\\n",
    "                                                                               random_state=seed, use_train=False)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    test_acc = 100.*correct/total\n",
    "    test_loss /= total\n",
    "    if update_strategy == 'on_test_acc_reduction':\n",
    "        if test_acc < last_acc:\n",
    "            if strategy in ['max_k_loss', 'min_k_loss', 'weighted_random_sampling']:\n",
    "                    dataloader.initialize_weights(criterion_fn(reduction='none'), device, seed=seed, \n",
    "                                                  dump='./dump_logs/{}_{}_{}.txt'.format(strategy, seed, 0))\n",
    "            if strategy in ['heterogeneous_max_k_loss', 'heterogeneous_min_k_loss']:\n",
    "                dataloader.initialize_weights_per_class(criterion_fn(reduction='none'), device, seed=seed)\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        net.save(best_acc, epoch, seed, strategy)\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| Seeds: [10, 42, 4]                                                                     |\n",
      "| Strategies: ['weighted_random_sampling']                                               |\n",
      "| -> Resulting number of iterations: 3                                                   |\n",
      "| Number of iterations: 100                                                              |\n",
      "| Learning rate: 0.01                                                                    |\n",
      "| Resuming from checkpoint: False                                                        |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| Seed: 10      Strategy: weighted_random_sampling                                                         |\n",
      "| Epoch         Train Accuracy  Test Accuracy   Train Loss   Test Loss                   |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| [001/100]:    33.74           34.76           0.03045      0.03159                     |\n",
      "| [002/100]:    32.06           31.56           0.03344      0.03682                     |\n",
      "| [003/100]:    34.14           33.77           0.03048      0.03279                     |\n",
      "| [004/100]:    40.88           41.29           0.02699      0.02816                     |\n",
      "| [005/100]:    39.31           39.54           0.02606      0.02637                     |\n",
      "| [006/100]:    44.13           42.53           0.02434      0.02736                     |\n",
      "| [007/100]:    41.61           42.08           00.0248      0.02513                     |\n",
      "| [008/100]:    48.64           48.49           0.02183      0.02278                     |\n",
      "| [009/100]:    41.28           41.82           0.02471      0.02636                     |\n",
      "| [010/100]:    50.17           47.65           0.02032      0.02432                     |\n",
      "| [011/100]:    45.75           43.54           0.02176      0.02453                     |\n",
      "| [012/100]:    49.37           47.82           0.02089      0.02345                     |\n",
      "| [013/100]:    50.53           48.84           0.02023      0.02334                     |\n",
      "| [014/100]:    51.29           48.26           0.02001      0.02528                     |\n",
      "| [015/100]:    50.68           47.96           0.01967      0.02301                     |\n",
      "| [016/100]:    52.51           52.48           0.01913      0.02119                     |\n",
      "| [017/100]:    50.17           047.9           0.02045      0.02332                     |\n",
      "| [018/100]:    56.39           53.79           0.01717      0.02057                     |\n",
      "| [019/100]:    56.59           53.91           0.01586      0.01825                     |\n",
      "| [020/100]:    56.26           51.93           0.01614      0.01972                     |\n",
      "| [021/100]:    55.38           51.59           0.01631      0.01951                     |\n",
      "| [022/100]:    61.49           58.19           00.0144      0.01732                     |\n",
      "| [023/100]:    56.15           52.84           0.01558      0.01955                     |\n",
      "| [024/100]:    62.25           59.07           0.01334      0.01594                     |\n",
      "| [025/100]:    59.01           54.23           0.01447      0.01724                     |\n",
      "| [026/100]:    62.38           58.98           0.01329      0.01658                     |\n",
      "| [027/100]:    59.78           55.41           0.01404      0.01702                     |\n",
      "| [028/100]:    63.62           58.93           0.01293      0.01685                     |\n",
      "| [029/100]:    63.01           59.11           00.0126      0.01539                     |\n",
      "| [030/100]:    61.95           056.6           0.01396      0.01864                     |\n",
      "| [031/100]:    63.79           58.43           0.01316      0.01698                     |\n",
      "| [032/100]:    65.04           59.78           0.01249      0.01588                     |\n",
      "| [033/100]:    63.14           57.68           0.01413      0.01795                     |\n",
      "| [034/100]:    66.73           62.34           00.0119      0.01533                     |\n",
      "| [035/100]:    60.04           54.09           0.01679      0.02191                     |\n",
      "| [036/100]:    69.15           64.08           0.01099      0.01462                     |\n",
      "| [037/100]:    59.88           056.1           0.01523      00.0188                     |\n",
      "| [038/100]:    67.45           60.62           0.01299      0.01863                     |\n",
      "| [039/100]:    64.01           58.13           0.01391      0.01833                     |\n",
      "| [040/100]:    67.07           60.84           0.01196      0.01671                     |\n",
      "| [041/100]:    69.63           63.47           0.01035      0.01419                     |\n",
      "| [042/100]:    66.12           58.16           0.01184      0.01616                     |\n",
      "| [043/100]:    70.25           62.24           0.01017      0.01478                     |\n",
      "| [044/100]:    69.67           62.88           0.01046      0.01472                     |\n",
      "| [045/100]:    67.25           59.12           0.01192      0.01701                     |\n",
      "| [046/100]:    69.73           62.52           0.01074      00.0155                     |\n",
      "| [047/100]:    69.87           62.47           0.01072      0.01527                     |\n",
      "| [048/100]:    69.77           62.54           0.01035      0.01534                     |\n",
      "| [049/100]:    70.06           60.29           0.01113      0.01717                     |\n",
      "| [050/100]:    67.55           60.29           00.0135      0.02019                     |\n",
      "| [051/100]:    67.48           58.91           0.01565      0.02251                     |\n",
      "| [052/100]:    72.68           63.98           0.01036      0.01669                     |\n",
      "| [053/100]:    68.66           61.57           0.01179      0.01678                     |\n",
      "| [054/100]:    72.55           63.24           00.0097      0.01584                     |\n",
      "| [055/100]:    072.2           63.37           0.01052      0.01603                     |\n",
      "| [056/100]:    072.0           63.95           0.01062      0.01668                     |\n",
      "| [057/100]:    66.81           58.43           000.014      0.01971                     |\n",
      "| [058/100]:    73.79           64.52           0.01061      0.01718                     |\n",
      "| [059/100]:    72.83           64.15           0.01075      0.01667                     |\n",
      "| [060/100]:    74.99           65.18           0.00926      0.01557                     |\n",
      "| [061/100]:    68.28           59.36           00.0138      0.02042                     |\n",
      "| [062/100]:    76.83           067.0           0.00869      0.01458                     |\n",
      "| [063/100]:    71.25           62.38           0.01153      0.01719                     |\n",
      "| [064/100]:    78.48           66.68           0.00772      0.01435                     |\n",
      "| [065/100]:    71.31           61.54           0.01085      0.01674                     |\n",
      "| [066/100]:    75.28           65.02           0.00947      0.01616                     |\n",
      "| [067/100]:    69.64           59.99           0.01294      0.02037                     |\n",
      "| [068/100]:    72.08           62.34           0.01152      00.0194                     |\n",
      "| [069/100]:    67.79           58.54           0.01346      0.02066                     |\n",
      "| [070/100]:    73.81           62.99           0.01001      0.01692                     |\n",
      "| [071/100]:    73.76           62.41           0.01011      0.01735                     |\n",
      "| [072/100]:    72.38           61.07           0.01036      0.01796                     |\n",
      "| [073/100]:    68.88           60.03           0.01322      0.01941                     |\n",
      "| [074/100]:    72.04           61.68           0.01074      0.01875                     |\n",
      "| [075/100]:    70.98           060.8           0.01207      0.01906                     |\n",
      "| [076/100]:    73.71           063.4           0.01017      0.01724                     |\n",
      "| [077/100]:    64.91           55.22           0.01581      0.02431                     |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| [078/100]:    073.3           62.53           0.01069      0.01801                     |\n",
      "| [079/100]:    066.2           57.54           0.01504      0.02301                     |\n",
      "| [080/100]:    75.54           65.42           0.00929      0.01611                     |\n",
      "| [081/100]:    69.78           058.0           0.01154      0.01981                     |\n",
      "| [082/100]:    73.53           62.43           0.01056      0.01815                     |\n",
      "| [083/100]:    74.61           62.15           0.00996      0.01837                     |\n",
      "| [084/100]:    75.97           63.93           00.0095      0.01665                     |\n",
      "| [085/100]:    73.29           60.98           0.01071      0.01924                     |\n",
      "| [086/100]:    73.33           62.28           0.00953      0.01719                     |\n",
      "| [087/100]:    69.66           58.45           0.01235      000.021                     |\n",
      "| [088/100]:    75.52           63.65           0.00919      0.01676                     |\n",
      "| [089/100]:    69.08           57.78           0.01319      0.02232                     |\n",
      "| [090/100]:    72.65           60.79           0.01107      00.0199                     |\n",
      "| [091/100]:    69.77           059.2           0.01308      0.02184                     |\n",
      "| [092/100]:    70.72           59.75           0.01197      0.02093                     |\n",
      "| [093/100]:    70.39           58.43           0.01218      0.02176                     |\n",
      "| [094/100]:    69.66           59.31           0.01264      0.02101                     |\n",
      "| [095/100]:    67.03           56.99           0.01381      0.02304                     |\n",
      "| [096/100]:    71.41           61.12           0.01109      0.01921                     |\n",
      "| [097/100]:    65.43           56.09           0.01549      0.02464                     |\n",
      "| [098/100]:    71.26           61.37           00.0119      0.01982                     |\n",
      "| [099/100]:    66.32           55.86           00.0151      0.02377                     |\n",
      "| [100/100]:    075.3           063.8           0.01036      0.01789                     |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| Seed: 42      Strategy: weighted_random_sampling                                                         |\n",
      "| Epoch         Train Accuracy  Test Accuracy   Train Loss   Test Loss                   |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| [001/100]:    36.75           037.5           0.03233      0.03315                     |\n",
      "| [002/100]:    32.46           33.57           0.03088      0.03168                     |\n",
      "| [003/100]:    36.71           35.95           0.03019      0.03338                     |\n",
      "| [004/100]:    038.2           38.42           0.02863      0.03046                     |\n",
      "| [005/100]:    39.41           38.24           0.02775      0.03167                     |\n",
      "| [006/100]:    42.59           043.3           0.02536      0.02794                     |\n",
      "| [007/100]:    42.23           42.04           0.02325      0.02423                     |\n",
      "| [008/100]:    46.88           47.01           0.02384      00.0256                     |\n",
      "| [009/100]:    44.86           44.01           0.02252      0.02477                     |\n",
      "| [010/100]:    46.14           44.29           0.02297      0.02644                     |\n",
      "| [011/100]:    48.65           48.61           0.02186      0.02427                     |\n",
      "| [012/100]:    48.24           45.18           0.02079      0.02445                     |\n",
      "| [013/100]:    52.38           49.86           0.01871      0.02232                     |\n",
      "| [014/100]:    49.96           48.77           0.01929      0.02135                     |\n",
      "| [015/100]:    53.45           051.1           0.01765      0.02069                     |\n",
      "| [016/100]:    53.47           050.7           0.01825      0.02165                     |\n",
      "| [017/100]:    54.43           52.25           0.01732      0.02062                     |\n",
      "| [018/100]:    54.45           51.46           00.0178      0.02077                     |\n",
      "| [019/100]:    54.81           52.09           0.01734      0.02002                     |\n",
      "| [020/100]:    55.65           53.04           0.01627      0.01939                     |\n",
      "| [021/100]:    55.93           052.0           00.0161      0.01983                     |\n",
      "| [022/100]:    57.56           54.51           0.01527      0.01823                     |\n",
      "| [023/100]:    58.68           54.82           0.01468      0.01786                     |\n",
      "| [024/100]:    59.97           57.13           0.01458      0.01707                     |\n",
      "| [025/100]:    58.05           54.37           0.01536      0.01847                     |\n",
      "| [026/100]:    62.97           58.31           0.01403      0.01798                     |\n",
      "| [027/100]:    55.27           51.88           0.01924      0.02297                     |\n",
      "| [028/100]:    63.34           60.12           0.01406      0.01765                     |\n",
      "| [029/100]:    59.07           54.26           0.01543      0.01868                     |\n",
      "| [030/100]:    62.72           058.7           0.01489      0.01862                     |\n",
      "| [031/100]:    55.17           50.42           0.02122      0.02653                     |\n",
      "| [032/100]:    59.81           54.33           0.01673      0.02232                     |\n",
      "| [033/100]:    60.77           55.99           0.01582      00.0195                     |\n",
      "| [034/100]:    63.56           58.47           0.01423      00.0195                     |\n",
      "| [035/100]:    61.83           56.39           0.01471      0.01932                     |\n",
      "| [036/100]:    66.81           61.66           0.01252      0.01702                     |\n",
      "| [037/100]:    65.26           058.8           0.01269      0.01692                     |\n",
      "| [038/100]:    065.7           59.66           00.0122      0.01713                     |\n",
      "| [039/100]:    62.31           56.74           0.01477      0.01989                     |\n",
      "| [040/100]:    69.31           61.63           0.01087      0.01636                     |\n",
      "| [041/100]:    61.92           53.96           0.01518      0.02157                     |\n",
      "| [042/100]:    71.19           63.09           0.01065      0.01597                     |\n",
      "| [043/100]:    60.42           53.82           0.01566      0.02132                     |\n",
      "| [044/100]:    071.2           63.43           0.01045      0.01605                     |\n",
      "| [045/100]:    62.94           55.47           0.01386      0.01919                     |\n",
      "| [046/100]:    71.18           64.05           0.01073      0.01603                     |\n",
      "| [047/100]:    64.76           58.03           0.01337      0.01837                     |\n",
      "| [048/100]:    69.68           61.11           0.01119      00.0175                     |\n",
      "| [049/100]:    067.5           60.63           0.01292      0.01716                     |\n",
      "| [050/100]:    69.69           60.71           0.01151      0.01805                     |\n",
      "| [051/100]:    69.65           60.93           0.01178      0.01686                     |\n",
      "| [052/100]:    72.82           62.13           0.00972      0.01647                     |\n",
      "| [053/100]:    70.48           61.22           0.01083      0.01581                     |\n",
      "| [054/100]:    66.75           58.38           0.01312      0.02014                     |\n",
      "| [055/100]:    70.65           60.61           0.01128      0.01704                     |\n",
      "| [056/100]:    66.01           57.01           0.01354      0.02045                     |\n",
      "| [057/100]:    073.1           63.58           0.01097      0.01647                     |\n",
      "| [058/100]:    65.41           56.17           0.01397      0.02088                     |\n",
      "| [059/100]:    70.96           61.82           0.01251      0.01888                     |\n",
      "| [060/100]:    70.31           61.89           0.01126      0.01743                     |\n",
      "| [061/100]:    70.68           61.92           0.01251      0.01792                     |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| [062/100]:    75.67           64.95           0.00865      0.01502                     |\n",
      "| [063/100]:    67.28           58.18           00.0143      00.0216                     |\n",
      "| [064/100]:    78.05           067.7           0.00891      0.01557                     |\n",
      "| [065/100]:    74.24           63.28           00.0104      00.0165                     |\n",
      "| [066/100]:    76.26           66.34           0.00909      00.0158                     |\n",
      "| [067/100]:    073.8           63.01           0.01147      0.01847                     |\n",
      "| [068/100]:    78.51           66.12           0.00789      00.0154                     |\n",
      "| [069/100]:    070.2           060.2           0.01256      0.01962                     |\n",
      "| [070/100]:    75.64           65.67           0.01057      0.01785                     |\n",
      "| [071/100]:    73.48           62.18           0.01254      0.02017                     |\n",
      "| [072/100]:    73.68           63.24           0.01211      0.01988                     |\n",
      "| [073/100]:    72.13           61.67           0.01248      0.01984                     |\n",
      "| [074/100]:    74.27           063.5           0.01098      0.01887                     |\n",
      "| [075/100]:    72.21           60.68           0.01233      0.02037                     |\n",
      "| [076/100]:    76.29           64.19           0.01027      0.01874                     |\n",
      "| [077/100]:    071.7           60.14           0.01297      0.02141                     |\n",
      "| [078/100]:    77.08           65.61           0.00924      00.0175                     |\n",
      "| [079/100]:    71.32           59.76           0.01198      00.0205                     |\n",
      "| [080/100]:    77.74           65.23           0.00903      0.01737                     |\n",
      "| [081/100]:    74.37           063.4           0.00977      0.01705                     |\n",
      "| [082/100]:    079.5           67.34           0.00837      0.01695                     |\n",
      "| [083/100]:    71.06           59.19           0.01298      0.02212                     |\n",
      "| [084/100]:    76.14           65.55           0.01012      0.01804                     |\n",
      "| [085/100]:    73.01           60.41           0.01151      0.02051                     |\n",
      "| [086/100]:    79.55           67.19           0.00917      0.01788                     |\n",
      "| [087/100]:    69.22           58.85           0.01414      0.02306                     |\n",
      "| [088/100]:    75.91           64.62           00.0107      0.01963                     |\n",
      "| [089/100]:    63.78           55.34           0.01772      0.02687                     |\n",
      "| [090/100]:    81.69           68.96           0.00807      0.01616                     |\n",
      "| [091/100]:    67.22           057.0           0.01592      0.02522                     |\n",
      "| [092/100]:    80.52           68.22           0.00891      00.0166                     |\n",
      "| [093/100]:    68.32           58.51           0.01557      0.02332                     |\n",
      "| [094/100]:    77.38           65.05           0.01062      0.01909                     |\n",
      "| [095/100]:    67.13           57.75           0.01649      0.02442                     |\n",
      "| [096/100]:    78.86           065.8           0.00896      00.0179                     |\n",
      "| [097/100]:    59.77           52.67           0.02091      0.02797                     |\n",
      "| [098/100]:    75.27           62.38           0.01088      0.02061                     |\n",
      "| [099/100]:    68.44           58.12           0.01722      0.02622                     |\n",
      "| [100/100]:    75.48           60.95           0.01047      0.02169                     |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| Seed: 04      Strategy: weighted_random_sampling                                                         |\n",
      "| Epoch         Train Accuracy  Test Accuracy   Train Loss   Test Loss                   |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| [001/100]:    33.33           33.76           0.03278      0.03442                     |\n",
      "| [002/100]:    31.67           33.73           00.0313      0.03069                     |\n",
      "| [003/100]:    36.53           36.29           0.02984      0.03137                     |\n",
      "| [004/100]:    39.36           39.39           0.02721      0.02853                     |\n",
      "| [005/100]:    41.23           42.85           0.02618      0.02652                     |\n",
      "| [006/100]:    38.31           37.75           0.02737      0.02885                     |\n",
      "| [007/100]:    44.62           44.55           0.02334      0.02571                     |\n",
      "| [008/100]:    42.44           42.14           0.02549      0.02776                     |\n",
      "| [009/100]:    045.2           44.49           0.02349      0.02552                     |\n",
      "| [010/100]:    046.5           45.18           0.02245      0.02549                     |\n",
      "| [011/100]:    46.79           45.21           0.02158      0.02424                     |\n",
      "| [012/100]:    47.36           47.71           0.02148      0.02255                     |\n",
      "| [013/100]:    47.05           46.04           0.02196      0.02375                     |\n",
      "| [014/100]:    050.3           49.24           00.0186      0.02056                     |\n",
      "| [015/100]:    50.99           49.56           0.01881      0.02118                     |\n",
      "| [016/100]:    53.94           53.28           0.01739      0.01876                     |\n",
      "| [017/100]:    53.04           50.14           0.01739      0.02043                     |\n",
      "| [018/100]:    52.79           48.17           0.01784      0.02225                     |\n",
      "| [019/100]:    55.55           053.6           0.01617      0.01851                     |\n",
      "| [020/100]:    54.28           049.9           0.01657      0.02076                     |\n",
      "| [021/100]:    59.53           56.63           0.01494      0.01744                     |\n",
      "| [022/100]:    53.03           48.46           0.01774      0.02177                     |\n",
      "| [023/100]:    58.98           54.97           0.01504      0.01862                     |\n",
      "| [024/100]:    56.91           53.94           0.01583      0.01854                     |\n",
      "| [025/100]:    061.2           57.93           0.01357      0.01658                     |\n",
      "| [026/100]:    55.77           52.42           0.01667      0.01977                     |\n",
      "| [027/100]:    58.96           53.35           00.0155      00.0202                     |\n",
      "| [028/100]:    63.01           58.59           0.01359      0.01749                     |\n",
      "| [029/100]:    59.27           54.53           0.01448      0.01819                     |\n",
      "| [030/100]:    60.87           56.17           0.01351      00.0169                     |\n",
      "| [031/100]:    61.53           56.57           0.01352      0.01782                     |\n",
      "| [032/100]:    64.64           60.05           0.01238      0.01551                     |\n",
      "| [033/100]:    59.07           53.06           0.01507      0.02014                     |\n",
      "| [034/100]:    66.52           59.64           0.01195      0.01615                     |\n",
      "| [035/100]:    57.76           51.22           0.01634      0.02221                     |\n",
      "| [036/100]:    67.77           62.34           0.01166      0.01613                     |\n",
      "| [037/100]:    56.08           49.75           0.01616      0.02148                     |\n",
      "| [038/100]:    67.99           62.21           0.01217      0.01624                     |\n",
      "| [039/100]:    59.13           51.02           0.01695      0.02373                     |\n",
      "| [040/100]:    67.03           60.44           0.01261      00.0172                     |\n",
      "| [041/100]:    56.54           048.6           00.0188      0.02707                     |\n",
      "| [042/100]:    65.83           60.43           0.01559      0.02027                     |\n",
      "| [043/100]:    64.98           56.63           0.01388      0.02062                     |\n",
      "| [044/100]:    67.27           60.42           0.01303      0.01857                     |\n",
      "| [045/100]:    63.58           55.07           0.01412      00.0207                     |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| [046/100]:    68.06           60.32           0.01194      0.01693                     |\n",
      "| [047/100]:    67.11           57.29           00.0121      0.01892                     |\n",
      "| [048/100]:    69.84           61.43           0.01156      0.01686                     |\n",
      "| [049/100]:    65.51           57.23           0.01342      0.02012                     |\n",
      "| [050/100]:    73.41           64.19           0.00962      0.01516                     |\n",
      "| [051/100]:    67.02           57.65           0.01238      0.01899                     |\n",
      "| [052/100]:    71.06           62.19           0.01094      0.01655                     |\n",
      "| [053/100]:    69.77           060.2           0.01148      0.01849                     |\n",
      "| [054/100]:    67.88           58.35           0.01297      0.01969                     |\n",
      "| [055/100]:    74.57           64.44           0.00894      0.01495                     |\n",
      "| [056/100]:    71.28           60.72           0.00996      0.01673                     |\n",
      "| [057/100]:    75.08           64.39           0.00867      0.01533                     |\n",
      "| [058/100]:    71.49           60.67           0.01058      0.01702                     |\n",
      "| [059/100]:    74.22           63.28           0.00928      0.01591                     |\n",
      "| [060/100]:    62.56           53.96           0.01743      0.02671                     |\n",
      "| [061/100]:    73.68           62.46           0.01072      00.0191                     |\n",
      "| [062/100]:    069.5           060.4           00.0122      0.01872                     |\n",
      "| [063/100]:    71.04           59.07           0.01179      0.02096                     |\n",
      "| [064/100]:    71.24           61.41           0.01173      0.01861                     |\n",
      "| [065/100]:    75.75           63.32           0.00923      0.01709                     |\n",
      "| [066/100]:    66.33           56.57           0.01447      0.02237                     |\n",
      "| [067/100]:    73.61           61.01           0.01009      0.01839                     |\n",
      "| [068/100]:    71.38           60.74           0.01194      0.01898                     |\n",
      "| [069/100]:    73.91           60.17           0.01012      0.01922                     |\n",
      "| [070/100]:    74.74           063.1           00.0103      00.0179                     |\n",
      "| [071/100]:    70.38           57.33           0.01239      0.02225                     |\n",
      "| [072/100]:    74.25           63.17           0.01095      00.0185                     |\n",
      "| [073/100]:    75.41           62.32           0.00962      0.01862                     |\n",
      "| [074/100]:    75.49           63.47           0.01069      00.0183                     |\n",
      "| [075/100]:    70.17           57.49           0.01211      0.02216                     |\n",
      "| [076/100]:    78.08           066.2           00.0093      0.01668                     |\n",
      "| [077/100]:    74.79           061.3           0.00977      0.01895                     |\n",
      "| [078/100]:    77.71           64.68           0.00953      0.01748                     |\n",
      "| [079/100]:    76.34           63.38           00.0091      0.01817                     |\n",
      "| [080/100]:    73.55           62.09           0.01199      0.02022                     |\n",
      "| [081/100]:    074.6           61.53           0.01041      0.01909                     |\n",
      "| [082/100]:    69.46           58.63           0.01491      00.0238                     |\n",
      "| [083/100]:    75.25           63.02           0.01132      0.02053                     |\n",
      "| [084/100]:    65.98           056.3           0.01594      0.02477                     |\n",
      "| [085/100]:    73.57           61.63           00.0124      0.02217                     |\n",
      "| [086/100]:    64.38           54.95           0.01657      0.02525                     |\n",
      "| [087/100]:    73.95           062.4           0.01159      00.0206                     |\n",
      "| [088/100]:    64.43           54.23           0.01708      0.02663                     |\n",
      "| [089/100]:    69.12           57.87           0.01431      0.02522                     |\n",
      "| [090/100]:    69.39           57.68           0.01277      0.02219                     |\n",
      "| [091/100]:    71.75           59.58           00.0117      0.02133                     |\n",
      "| [092/100]:    65.72           56.33           0.01616      00.0252                     |\n",
      "| [093/100]:    72.84           60.41           0.01235      0.02216                     |\n",
      "| [094/100]:    69.59           058.7           0.01417      0.02383                     |\n",
      "| [095/100]:    073.2           60.45           0.01201      0.02244                     |\n",
      "| [096/100]:    67.09           56.42           0.01462      0.02451                     |\n",
      "| [097/100]:    72.77           61.55           0.01234      0.02107                     |\n",
      "| [098/100]:    66.73           56.44           0.01468      0.02488                     |\n",
      "| [099/100]:    74.45           63.08           0.01109      0.01914                     |\n",
      "| [100/100]:    62.54           52.91           00.0158      0.02603                     |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "\n",
      "Finished training. Time needed: 56 hrs 4 mins 43 secs\n"
     ]
    }
   ],
   "source": [
    "resume = False\n",
    "given_date = '20191113' #only needed if resumed from checkpoint\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "### task: classification of the following classes\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    \n",
    "### hyperparameters\n",
    "test_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "num_epochs = 100 # number of epochs the model gets trained\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "batch_size = 100\n",
    "weight_decay = 5e-4\n",
    "\n",
    "print(\"Begin training.\")\n",
    "start = timeit.default_timer()\n",
    "#Logging header\n",
    "length_table = 90\n",
    "log_separating_line(length_table)\n",
    "log_header_line(\"Seeds: {}\".format(SEEDS), length_table)\n",
    "log_header_line(\"Strategies: {}\".format(STRATEGIES), length_table)\n",
    "log_header_line(\"-> Resulting number of iterations: {}\".format(len(SEEDS) * len(STRATEGIES)), length_table)\n",
    "log_header_line(\"Number of iterations: {}\".format(num_epochs), length_table)\n",
    "log_header_line(\"Learning rate: {}\".format(learning_rate), length_table)\n",
    "log_header_line(\"Resuming from checkpoint: {}\".format(True if resume else False), length_table)\n",
    "log_separating_line(length_table)\n",
    "\n",
    "rows = []\n",
    "for seed in SEEDS:\n",
    "    for strategy in STRATEGIES:\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "             \n",
    "        ### Model\n",
    "        net = ResNet18()\n",
    "        net = net.to(device)\n",
    "        criterion = nn.CrossEntropyLoss # no function!\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "        \n",
    "        ### load the data\n",
    "        # if needed, specify batch sizes and shuffle settings\n",
    "        dataloader = DataLoader(batch_size=batch_size)\n",
    "        dataloader.download_cifar()\n",
    "        dataloader.set_model(net)\n",
    "        \n",
    "        if strategy in ['max_k_loss', 'min_k_loss', 'weighted_random_sampling']:\n",
    "            dataloader.initialize_weights(criterion(reduction='none'), device, seed=seed, \n",
    "                                          dump='./dump_logs/{}_{}_{}.txt'.format(strategy, seed, 0))\n",
    "        if strategy in ['heterogeneous_max_k_loss', 'heterogeneous_min_k_loss']:\n",
    "            dataloader.initialize_weights_per_class(criterion(reduction='none'), device, seed=seed)\n",
    "        last_acc = 0\n",
    "            \n",
    "        print()\n",
    "        log_separating_line(length_table)\n",
    "        log_position_header(seed, strategy, length_table)\n",
    "        log_separating_line(length_table)\n",
    "\n",
    "        if resume:\n",
    "            assert os.path.isdir('serialized'), 'Error: no serialized directory found!'\n",
    "            ckpt = torch.load('./serialized/{}/{}_ckpt_{}.pth'.format(given_date, strategy, seed))\n",
    "            test_acc, start_epoch, net = net.load(ckpt)\n",
    "\n",
    "        for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "            if update_strategy == 'every_epoch':\n",
    "                if strategy in ['max_k_loss', 'min_k_loss', 'weighted_random_sampling']:\n",
    "                    dataloader.initialize_weights(criterion(reduction='none'), device, seed=seed, \n",
    "                                                  dump='./dump_logs/{}_{}_{}.txt'.format(strategy, seed, epoch))\n",
    "                if strategy in ['heterogeneous_max_k_loss', 'heterogeneous_min_k_loss']:\n",
    "                    dataloader.initialize_weights_per_class(criterion(reduction='none'), device, seed=seed)\n",
    "\n",
    "            train_acc, train_loss = train(epoch, optimizer, criterion, seed, dataloader, \\\n",
    "                                          strategy, device, update_strategy)\n",
    "            test_acc, test_loss = test(epoch, test_acc, criterion, seed, dataloader, strategy, device, last_acc, update_strategy)\n",
    "            log_position_line(epoch + 1, num_epochs, train_acc, test_acc, train_loss, test_loss, length_table)\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'seed': seed,\n",
    "                'train': True,\n",
    "                'strategy': strategy,\n",
    "                'accuracy': train_acc,\n",
    "                'loss': train_loss\n",
    "            }\n",
    "            rows.append(row)\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'seed': seed,\n",
    "                'train': False,\n",
    "                'strategy': strategy,\n",
    "                'accuracy': test_acc,\n",
    "                'loss': test_loss\n",
    "            }\n",
    "            rows.append(row)\n",
    "        log_separating_line(length_table)\n",
    "            \n",
    "stop = timeit.default_timer()\n",
    "time_needed = stop - start\n",
    "hrs = int(time_needed / 3600)\n",
    "mins = int((time_needed / 60) % 60)\n",
    "secs = int(time_needed % 60)\n",
    "print()\n",
    "print(\"Finished training. Time needed: {} hrs {} mins {} secs\".format(hrs, mins, secs))\n",
    "\n",
    "logging_df = pd.DataFrame(rows, columns=['epoch', 'seed', 'train', 'strategy', 'accuracy', 'loss'])   \n",
    "training_logs_dir = 'evaluation_logs'\n",
    "logging_df.to_csv('{}.txt'.format(os.path.join(training_logs_dir, today)), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
