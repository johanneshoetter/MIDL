{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Intelligence with Deep Learning\n",
    "## Importance batching for improved training of neural networks\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import ResNet18\n",
    "from utils.data_utils import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "today = datetime.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [10]#, 42, 4] # don't change!\n",
    "STRATEGIES = ['freeze']#, 'shuffle', 'homogeneous', 'heterogeneous'] # can be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training\n",
    "def train(epoch, optimizer, criterion, dataloader):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader.yield_batches(use_train=True)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    train_acc = 100.*correct/total\n",
    "    train_loss /= total\n",
    "    return train_acc, train_loss\n",
    "\n",
    "### Testing\n",
    "def test(epoch, best_acc, seed, dataloader):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader.yield_batches(use_train=False)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    test_acc = 100.*correct/total\n",
    "    test_loss /= total\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        print(\"==> Saving to checkpoint..\")\n",
    "        net.save(best_acc, epoch, seed, strategy)\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training..\n",
      "+------------------------------+\n",
      "| Seeds: [[10]] |\n",
      "\n",
      "==> Beginning training with seed 10 and strategy freeze\n",
      "------------------------------\n",
      "==> Building model..\n",
      "==> Loading data..\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Resetting learning rate\n",
      "==> Saving to checkpoint..\n",
      "[1/1]: Train Acc: 31.036 | Test Acc: 43.68 | Train Loss: 0.029438955476284025 | Test Loss: 0.023819254112243653\n",
      "61.4310292\n"
     ]
    }
   ],
   "source": [
    "resume = False\n",
    "given_date = '20191113'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "### task: classification of the following classes\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    \n",
    "### hyperparameters\n",
    "test_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "num_epochs = 1 # number of iterations the model gets trained\n",
    "learning_rates = { # learning rate is reset after specific epochs\n",
    "    '1': 0.1,\n",
    "    '150': 0.01,\n",
    "    '250': 0.001\n",
    "}\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "print(\"Begin training..\")\n",
    "#Logging header\n",
    "\n",
    "rows = []\n",
    "for seed in SEEDS:\n",
    "    for strategy in STRATEGIES:\n",
    "        print(\"\\n==> Beginning training with seed {} and strategy {}\".format(seed, strategy))\n",
    "        print(\"-\" * 30)\n",
    "        torch.manual_seed(seed)\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "             \n",
    "        ### Model\n",
    "        print('==> Building model..')\n",
    "        net = ResNet18()\n",
    "        net = net.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rates['1'], momentum=momentum, weight_decay=weight_decay)\n",
    "        \n",
    "        ### load the data\n",
    "        # if needed, specify batch sizes and shuffle settings\n",
    "        print('==> Loading data..')\n",
    "        dataloader = DataLoader()\n",
    "        dataloader.download_cifar()\n",
    "        dataloader.prepare_cifar(strategy, random_state=seed, batch_size=64)\n",
    "\n",
    "        if resume:\n",
    "            print('==> Resuming from checkpoint..')\n",
    "            assert os.path.isdir('serialized'), 'Error: no serialized directory found!'\n",
    "            ckpt = torch.load('./serialized/{}/{}_ckpt_{}.pth'.format(given_date, strategy, seed))\n",
    "            test_acc, start_epoch, net = net.load(ckpt)\n",
    "\n",
    "        for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "            if str(epoch+1) in learning_rates.keys():\n",
    "                print('==> Resetting learning rate')\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = learning_rates[str(epoch+1)]\n",
    "                    \n",
    "            train_acc, train_loss = train(epoch, optimizer, criterion, dataloader)\n",
    "            test_acc, test_loss = test(epoch, test_acc, seed, dataloader)\n",
    "            print(\"[{}/{}]: Train Acc: {} | Test Acc: {} | Train Loss: {} | Test Loss: {}\"\\\n",
    "                  .format(epoch+1, num_epochs, train_acc, test_acc, train_loss, test_loss))\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'seed': seed,\n",
    "                'train': True,\n",
    "                'strategy': strategy,\n",
    "                'accuracy': train_acc,\n",
    "                'loss': train_loss\n",
    "            }\n",
    "            rows.append(row)\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'seed': seed,\n",
    "                'train': False,\n",
    "                'strategy': strategy,\n",
    "                'accuracy': test_acc,\n",
    "                'loss': test_loss\n",
    "            }\n",
    "            rows.append(row)\n",
    "            \n",
    "stop = timeit.default_timer()\n",
    "logging_df = pd.DataFrame(rows, columns=['epoch', 'seed', 'train', 'strategy', 'accuracy', 'loss'])   \n",
    "training_logs_dir = 'evaluation_logs'\n",
    "logging_df.to_csv('{}.txt'.format(os.path.join(training_logs_dir, today)), sep='\\t', index=False)\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| Seeds: [10]                                                                            | 90\n",
      "| Strategies: ['freeze']                                                                 | 90\n",
      "| -> Resulting number of iterations: 1                                                   | 90\n",
      "| Number of iterations: 300                                                              | 90\n",
      "| Learning rates: {'1': 0.1, '150': 0.01, '250': 0.001}                                  | 90\n",
      "| Resuming from checkpoint: False                                                        | 90\n",
      "+----------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+----------------------------------------------------------------------------------------+\n",
      "Finished training. Time needed: 0 hrs 0 mins 0 secs\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin training.\")\n",
    "start = timeit.default_timer()\n",
    "#Logging header\n",
    "length_table = 90\n",
    "log_separating_line(length_table)\n",
    "log_header_line(\"Seeds: {}\".format(SEEDS), length_table)\n",
    "log_header_line(\"Strategies: {}\".format(STRATEGIES), length_table)\n",
    "log_header_line(\"-> Resulting number of iterations: {}\".format(len(SEEDS) * len(STRATEGIES)), length_table)\n",
    "log_header_line(\"Number of iterations: {}\".format(num_epochs), length_table)\n",
    "log_header_line(\"Learning rates: {}\".format(learning_rates), length_table)\n",
    "log_header_line(\"Resuming from checkpoint: {}\".format(True if resume else False), length_table)\n",
    "log_separating_line(length_table)\n",
    "print()\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "time_needed = stop - start\n",
    "hrs = int(time_needed / 3600)\n",
    "mins = int((time_needed / 60) % 60)\n",
    "secs = int(time_needed % 60)\n",
    "print()\n",
    "log_separating_line(length_table)\n",
    "print(\"Finished training. Time needed: {} hrs {} mins {} secs\".format(hrs, mins, secs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------+\n",
      "| Seed: 10    Strategy: freeze                                                           |\n",
      "| Epoch         Train Accuracy  Test Accuracy   Train Loss   Test Loss                   |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| [000/300]:    31.04           43.68           0.02944      0.02382                     |\n",
      "+----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "def log_separating_line(length_table):\n",
    "    filling_chars = \"-\" * (length_table - 2)\n",
    "    separating_line = \"+{}+\".format(filling_chars)\n",
    "    print(separating_line)\n",
    "    \n",
    "def log_header_line(line, length_table, oc_char='|'):\n",
    "    filling_ws = \" \" * (length_table - len(line) - 3)\n",
    "    logged_line = \"{} {}{}{}\".format(oc_char, line, filling_ws, oc_char)\n",
    "    print(logged_line)\n",
    "    \n",
    "def log_position_header(seed, strategy, length_table, oc_char='|'):\n",
    "    filling_ws = ' ' * (length_table - 31)\n",
    "    logged_line_1 = \"{} Seed: {}    Strategy: {}{}{}\".format(oc_char, str(seed).zfill(2), strategy, filling_ws, oc_char)\n",
    "    filling_ws = ' ' * (length_table - 71)\n",
    "    logged_line_2 = \"{} Epoch         Train Accuracy  Test Accuracy   Train Loss   Test Loss{}{}\"\\\n",
    "        .format(oc_char, filling_ws, oc_char)\n",
    "    print(logged_line_1)\n",
    "    print(logged_line_2)\n",
    "    \n",
    "def log_position_line(epoch, num_epochs, train_acc, test_acc, train_loss, test_loss, length_table, oc_char='|'):\n",
    "    epoch = str(epoch).zfill(len(str(num_epochs))) # leading zeros\n",
    "    train_acc = str(np.round(train_acc, 2)).zfill(5)\n",
    "    test_acc = str(np.round(test_acc, 2)).zfill(5)\n",
    "    train_loss = str(np.round(train_loss, 5)).zfill(7)\n",
    "    test_loss = str(np.round(test_loss, 5)).zfill(7)\n",
    "    filling_ws = ' ' * (length_table - 69 )\n",
    "    logged_line = \"{} [{}/{}]:    {}           {}           {}      {}{}{}\"\\\n",
    "        .format(oc_char, epoch, num_epochs, train_acc, test_acc, train_loss, test_loss, filling_ws, oc_char)\n",
    "    print(logged_line)\n",
    "    \n",
    "log_separating_line(length_table)\n",
    "log_position_header(seed, strategy, length_table)\n",
    "log_separating_line(length_table)\n",
    "log_position_line(epoch, num_epochs, train_acc, test_acc, train_loss, test_loss, length_table)\n",
    "log_separating_line(length_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resume = False\n",
    "given_date = '20191113'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "### task: classification of the following classes\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    \n",
    "### hyperparameters\n",
    "test_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "num_epochs = 300 # number of iterations the model gets trained\n",
    "learning_rate = 0.1 # factor for weight updates\n",
    "learning_rate_switches = { # learning rate is reset after specific epochs\n",
    "    '150': 0.01,\n",
    "    '250': 0.001\n",
    "}\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "rows = []\n",
    "for seed in SEEDS:\n",
    "    for shuffle_setting in [{'train': False, 'test': False}]:#, {'train': True, 'test': True}]:\n",
    "        print(\"\\n==> Beginning training with seed {} and shuffle setting {}\".format(seed, shuffle_setting))\n",
    "        print(\"-\" * 30)\n",
    "        torch.manual_seed(seed)\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "             \n",
    "        ### Model\n",
    "        print('==> Building model..')\n",
    "        net = ResNet18()\n",
    "        net = net.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "        \n",
    "        ### load the data\n",
    "        # if needed, specify batch sizes and shuffle settings\n",
    "        print('==> Loading data..')\n",
    "        dataloader = DataLoader()\n",
    "        dataloader.download_cifar()\n",
    "        dataloader.prepare_cifar('homogeneous', random_state=seed, batch_size=64)\n",
    "\n",
    "        if resume:\n",
    "            print('==> Resuming from checkpoint..')\n",
    "            assert os.path.isdir('serialized'), 'Error: no serialized directory found!'\n",
    "            ckpt = torch.load('./serialized/{}/ckpt_{}.pth'.format(given_date, seed))\n",
    "            test_acc, start_epoch, net = net.load(ckpt)\n",
    "\n",
    "        for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "            if str(epoch+1) in learning_rate_switches.keys():\n",
    "                print('==> Resetting learning rate')\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = learning_rate_switches[str(epoch+1)]\n",
    "                    \n",
    "            train_acc, train_loss = train(epoch, optimizer, criterion, dataloader)\n",
    "            test_acc, test_loss = test(epoch, test_acc, seed, dataloader)\n",
    "            print(\"[{}/{}]: Train Acc: {} | Test Acc: {} | Train Loss: {} | Test Loss: {}\"\\\n",
    "                  .format(epoch+1, num_epochs, train_acc, test_acc, train_loss, test_loss))\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'seed': seed,\n",
    "                'train': True,\n",
    "                'shuffle': True if shuffle_setting['train'] == True else False,\n",
    "                'accuracy': train_acc,\n",
    "                'loss': train_loss\n",
    "            }\n",
    "            rows.append(row)\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'seed': seed,\n",
    "                'train': False,\n",
    "                'shuffle': True if shuffle_setting['train'] == True else False,\n",
    "                'accuracy': test_acc,\n",
    "                'loss': test_loss\n",
    "            }\n",
    "            rows.append(row)\n",
    "            \n",
    "stop = timeit.default_timer()\n",
    "logging_df = pd.DataFrame(rows, columns=['epoch', 'seed', 'train', 'shuffle', 'accuracy', 'loss'])   \n",
    "training_logs_dir = 'training_logs'\n",
    "logging_df.to_csv('{}.txt'.format(os.path.join(training_logs_dir, today)), sep='\\t', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
