{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Intelligence with Deep Learning\n",
    "## Importance batching for improved training of neural networks\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import ResNet18\n",
    "from utils.data_utils import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "today = datetime.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [10, 42, 4] # don't change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training\n",
    "def train(epoch, optimizer, criterion, dataloader):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader.yield_batches(use_train=True)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    train_acc = 100.*correct/total\n",
    "    train_loss /= total\n",
    "    return train_acc, train_loss\n",
    "\n",
    "### Testing\n",
    "def test(epoch, best_acc, seed, dataloader):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader.yield_batches(use_train=False)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    test_acc = 100.*correct/total\n",
    "    test_loss /= total\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        print(\"==> Saving to checkpoint..\")\n",
    "        net.save(best_acc, epoch, seed)\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Beginning training with seed 10 and shuffle setting {'train': False, 'test': False}\n",
      "------------------------------\n",
      "==> Building model..\n",
      "==> Loading data..\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Saving to checkpoint..\n",
      "[1/300]: Train Acc: 85.628 | Test Acc: 10.0 | Train Loss: 0.02803756121143699 | Test Loss: 0.2070548736318946\n",
      "[2/300]: Train Acc: 81.68 | Test Acc: 10.0 | Train Loss: 0.026427149031609296 | Test Loss: 0.20097469370514154\n",
      "[3/300]: Train Acc: 81.68 | Test Acc: 10.0 | Train Loss: 0.026225016221106054 | Test Loss: 0.19873998127430678\n",
      "[4/300]: Train Acc: 81.552 | Test Acc: 10.0 | Train Loss: 0.026128724949210883 | Test Loss: 0.19835535020828246\n",
      "[5/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026110236986130474 | Test Loss: 0.19830398073196412\n",
      "[6/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610622972726822 | Test Loss: 0.1983169355392456\n",
      "[7/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610554798170924 | Test Loss: 0.19833677368164063\n",
      "[8/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610549770846963 | Test Loss: 0.19835204935073852\n",
      "[9/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026105805991292 | Test Loss: 0.19836240224838256\n",
      "[10/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026105978469997643 | Test Loss: 0.19836892404556275\n",
      "[11/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610615411877632 | Test Loss: 0.19837169246673583\n",
      "[12/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106223412454128 | Test Loss: 0.19837261924743652\n",
      "[13/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610628618568182 | Test Loss: 0.19837300844192504\n",
      "[14/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610630999326706 | Test Loss: 0.1983730549812317\n",
      "[15/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106316409111024 | Test Loss: 0.19837287578582763\n",
      "[16/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631087064743 | Test Loss: 0.19837288122177124\n",
      "[17/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313267946244 | Test Loss: 0.19837283849716186\n",
      "[18/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106309241056443 | Test Loss: 0.19837282638549805\n",
      "[19/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307574510573 | Test Loss: 0.19837280406951904\n",
      "[20/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308472156524 | Test Loss: 0.19837280254364015\n",
      "[21/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307582855225 | Test Loss: 0.19837279539108277\n",
      "[22/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308109760286 | Test Loss: 0.19837279539108277\n",
      "[23/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[24/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[25/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[26/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[27/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[28/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[29/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[30/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[31/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[32/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[33/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[34/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[35/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[36/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[37/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[38/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[39/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[40/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[41/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[42/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[43/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[44/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[45/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[46/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[47/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[48/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[49/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[50/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[51/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[52/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[53/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[54/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[55/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[56/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[57/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[58/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[59/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[60/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[61/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[62/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[63/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[64/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[65/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[66/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[67/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[68/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[69/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[70/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[71/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[73/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[74/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[75/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[76/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[77/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[78/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[79/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[80/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[81/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[82/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[83/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[84/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[85/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[86/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[87/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[88/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[89/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[90/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[91/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[92/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[93/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[94/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[95/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[96/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[97/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[98/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[99/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[100/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[101/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[102/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[103/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[104/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[105/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[106/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[107/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[108/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[109/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[110/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[111/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[112/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[113/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[114/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[115/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[116/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[117/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[118/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[119/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[120/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[121/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[122/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[123/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[124/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[125/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[126/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[127/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[128/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[129/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[130/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[131/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[132/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[133/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[134/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[135/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[136/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[137/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[138/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[139/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[140/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[141/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[142/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[143/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[144/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[145/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[146/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[147/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "[148/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106308497190474 | Test Loss: 0.19837279539108277\n",
      "[149/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106307830810548 | Test Loss: 0.19837279539108277\n",
      "==> Resetting learning rate\n",
      "[150/300]: Train Acc: 38.416 | Test Acc: 10.0 | Train Loss: 0.045051663065552715 | Test Loss: 0.0600792416036129\n",
      "[151/300]: Train Acc: 50.32 | Test Acc: 10.0 | Train Loss: 0.028086332674622537 | Test Loss: 0.059488871389627454\n",
      "[152/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028281740535497667 | Test Loss: 0.05944687328338623\n",
      "[153/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284539038538933 | Test Loss: 0.0594447598695755\n",
      "[154/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828438790798187 | Test Loss: 0.05944467459321022\n",
      "[155/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437099635601 | Test Loss: 0.05944467561841011\n",
      "[156/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437114953995 | Test Loss: 0.059444676357507706\n",
      "[157/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437093615532 | Test Loss: 0.05944467561841011\n",
      "[158/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371275901794 | Test Loss: 0.059444676357507706\n",
      "[159/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437083721161 | Test Loss: 0.05944467561841011\n",
      "[160/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370827674866 | Test Loss: 0.05944467716813087\n",
      "[161/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437115371227 | Test Loss: 0.05944467561841011\n",
      "[162/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371030926705 | Test Loss: 0.059444676452875135\n",
      "[163/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371154904366 | Test Loss: 0.059444676357507706\n",
      "[164/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370995759964 | Test Loss: 0.05944467561841011\n",
      "[165/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371250867843 | Test Loss: 0.059444676452875135\n",
      "[166/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437137782574 | Test Loss: 0.059444676357507706\n",
      "[167/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437100291252 | Test Loss: 0.059444676357507706\n",
      "[168/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370554089545 | Test Loss: 0.05944467561841011\n",
      "[169/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370933771133 | Test Loss: 0.059444676357507706\n",
      "[170/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437059879303 | Test Loss: 0.05944467561841011\n",
      "[171/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371092319488 | Test Loss: 0.059444676357507706\n",
      "[172/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437124311924 | Test Loss: 0.059444676357507706\n",
      "[173/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371175169944 | Test Loss: 0.059444676357507706\n",
      "[174/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371237754822 | Test Loss: 0.059444676357507706\n",
      "[175/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371175169944 | Test Loss: 0.059444676357507706\n",
      "[176/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437128126621 | Test Loss: 0.059444676452875135\n",
      "[177/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437118768692 | Test Loss: 0.059444676357507706\n",
      "[178/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371031522752 | Test Loss: 0.059444676452875135\n",
      "[179/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370471835137 | Test Loss: 0.05944467633366585\n",
      "[180/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370869994163 | Test Loss: 0.059444676357507706\n",
      "[181/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371044635773 | Test Loss: 0.059444676452875135\n",
      "[182/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437078535557 | Test Loss: 0.05944467633366585\n",
      "[183/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370734095572 | Test Loss: 0.059444676452875135\n",
      "[184/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370710253717 | Test Loss: 0.059444676357507706\n",
      "[185/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371079206467 | Test Loss: 0.059444676357507706\n",
      "[186/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437117755413 | Test Loss: 0.05944467633366585\n",
      "[187/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371014237406 | Test Loss: 0.059444676357507706\n",
      "[188/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370958209036 | Test Loss: 0.059444676452875135\n",
      "[189/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437054038048 | Test Loss: 0.059444676452875135\n",
      "[190/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370388388633 | Test Loss: 0.059444676452875135\n",
      "[191/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370527863503 | Test Loss: 0.05944467716813087\n",
      "[192/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370743632315 | Test Loss: 0.059444676452875135\n",
      "[193/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370953440666 | Test Loss: 0.059444676452875135\n",
      "[194/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370465874672 | Test Loss: 0.059444676452875135\n",
      "[195/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370381236077 | Test Loss: 0.059444676452875135\n",
      "[196/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[197/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[198/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[199/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[200/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[201/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[202/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[203/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[204/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[205/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[206/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[207/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[208/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[209/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[210/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[211/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[212/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[213/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[214/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[215/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[216/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[217/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[218/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[219/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[220/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[221/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[222/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[223/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[224/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[225/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[226/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[227/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[228/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[229/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[230/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[231/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[232/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[233/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[234/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[235/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[236/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[237/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[238/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[239/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[240/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[241/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[242/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[243/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[244/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[245/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[246/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[247/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[248/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "[249/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386004447 | Test Loss: 0.059444676452875135\n",
      "==> Resetting learning rate\n",
      "[250/300]: Train Acc: 7.696 | Test Acc: 10.0 | Train Loss: 0.04480440572023392 | Test Loss: 0.03880272789001465\n",
      "[251/300]: Train Acc: 5.648 | Test Acc: 10.0 | Train Loss: 0.03816364344596863 | Test Loss: 0.037132333719730376\n",
      "[252/300]: Train Acc: 3.728 | Test Acc: 10.0 | Train Loss: 0.03728373791217804 | Test Loss: 0.03672420790195465\n",
      "[253/300]: Train Acc: 2.704 | Test Acc: 10.0 | Train Loss: 0.03702613083124161 | Test Loss: 0.036584485387802124\n",
      "[254/300]: Train Acc: 1.936 | Test Acc: 10.0 | Train Loss: 0.036930374779701236 | Test Loss: 0.036528972029685976\n",
      "[255/300]: Train Acc: 1.424 | Test Acc: 10.0 | Train Loss: 0.03689074083328247 | Test Loss: 0.03650527329444885\n",
      "[256/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.0368734770154953 | Test Loss: 0.0364947919011116\n",
      "[257/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03686577250480652 | Test Loss: 0.036490085136890414\n",
      "[258/300]: Train Acc: 1.168 | Test Acc: 10.0 | Train Loss: 0.03686229681491852 | Test Loss: 0.036487952208518984\n",
      "[259/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03686072152614594 | Test Loss: 0.03648697754144668\n",
      "[260/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.0368600043964386 | Test Loss: 0.03648654294013977\n",
      "[261/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685967801570892 | Test Loss: 0.03648634736537933\n",
      "[262/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685953016757965 | Test Loss: 0.03648624954223633\n",
      "[263/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859462337493896 | Test Loss: 0.03648621118068695\n",
      "[264/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685943227291107 | Test Loss: 0.03648618986606598\n",
      "[265/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685941823005676 | Test Loss: 0.03648617708683014\n",
      "[266/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859411425590516 | Test Loss: 0.03648617565631866\n",
      "[267/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940918922424 | Test Loss: 0.03648617358207703\n",
      "[268/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859407801628115 | Test Loss: 0.03648617479801178\n",
      "[269/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940724849701 | Test Loss: 0.03648617502450943\n",
      "[270/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940654754639 | Test Loss: 0.03648617478609085\n",
      "[271/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940639972687 | Test Loss: 0.03648617466688156\n",
      "[272/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940639019013 | Test Loss: 0.036486173927783964\n",
      "[273/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406299591065 | Test Loss: 0.036486173927783964\n",
      "[274/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406323432924 | Test Loss: 0.03648617407083511\n",
      "[275/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03648617407083511\n",
      "[276/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.0368594063282013 | Test Loss: 0.03648617407083511\n",
      "[277/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[278/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[279/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[280/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[281/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[282/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[283/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[284/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[285/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[286/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[287/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[288/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[289/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[290/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[291/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[292/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[293/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[294/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[295/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[296/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[297/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[298/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[299/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "[300/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940633296966 | Test Loss: 0.03648617407083511\n",
      "\n",
      "==> Beginning training with seed 42 and shuffle setting {'train': False, 'test': False}\n",
      "------------------------------\n",
      "==> Building model..\n",
      "==> Loading data..\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1/300]: Train Acc: 86.386 | Test Acc: 10.0 | Train Loss: 0.026740696907788516 | Test Loss: 0.2102917844891548\n",
      "[2/300]: Train Acc: 81.552 | Test Acc: 10.0 | Train Loss: 0.02657303410857916 | Test Loss: 0.20142554817944766\n",
      "[3/300]: Train Acc: 81.68 | Test Acc: 10.0 | Train Loss: 0.026201140740066766 | Test Loss: 0.19970331316143275\n",
      "[4/300]: Train Acc: 81.552 | Test Acc: 10.0 | Train Loss: 0.02612878769814968 | Test Loss: 0.1993285295009613\n",
      "[5/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610904902651906 | Test Loss: 0.19930574584007263\n",
      "[6/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026105244468450545 | Test Loss: 0.19933996767997741\n",
      "[7/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610494011849165 | Test Loss: 0.19937324442863463\n",
      "[8/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026105298237800598 | Test Loss: 0.19939535222053528\n",
      "[9/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610565867766738 | Test Loss: 0.19940893154144287\n",
      "[10/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026105877918601035 | Test Loss: 0.1994174723148346\n",
      "[11/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106149163097142 | Test Loss: 0.19942056355476379\n",
      "[12/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610623704239726 | Test Loss: 0.1994215320110321\n",
      "[13/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610629687026143 | Test Loss: 0.19942186098098755\n",
      "[14/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.19942183594703675\n",
      "[15/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106324260234834 | Test Loss: 0.19942174820899963\n",
      "[16/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106319396495818 | Test Loss: 0.1994216562271118\n",
      "[17/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631640434265 | Test Loss: 0.199421586561203\n",
      "[18/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631422638893 | Test Loss: 0.19942158074378968\n",
      "[19/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314598321915 | Test Loss: 0.19942156162261962\n",
      "[20/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312893629073 | Test Loss: 0.19942156944274902\n",
      "[21/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313343048096 | Test Loss: 0.1994215452671051\n",
      "[22/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063123857975 | Test Loss: 0.199421537733078\n",
      "[23/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310905218123 | Test Loss: 0.1994215452671051\n",
      "[24/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314735412597 | Test Loss: 0.19942154669761658\n",
      "[25/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312800645827 | Test Loss: 0.19942154812812804\n",
      "[26/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312021017073 | Test Loss: 0.19942154812812804\n",
      "[27/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631275653839 | Test Loss: 0.19942155394554137\n",
      "[28/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314979791642 | Test Loss: 0.19942155394554137\n",
      "[29/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[30/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[31/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[32/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[33/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[34/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[35/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[36/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[37/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[38/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[39/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[40/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[41/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[42/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[43/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[44/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[45/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[46/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[47/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[48/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[49/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[50/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[51/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[52/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[53/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[54/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[55/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[56/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[57/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[58/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[59/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[61/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[62/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[63/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[64/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[65/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[66/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[67/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[68/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[69/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[70/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[71/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[72/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[73/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[74/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[75/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[76/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[77/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[78/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[79/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[80/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[81/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[82/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[83/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[84/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[85/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[86/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[87/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[88/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[89/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[90/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[91/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[92/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[93/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[94/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[95/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[96/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[97/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[98/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[99/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[100/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[101/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[102/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[103/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[104/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[105/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[106/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[107/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[108/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[109/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[110/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[111/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[112/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[113/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[114/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[115/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[116/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[117/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[118/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[119/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[120/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[121/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[122/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[123/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[124/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[125/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[126/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[127/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[128/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[129/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[130/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[131/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[132/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[133/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[134/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[135/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[136/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[137/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[138/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[139/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[140/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[141/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[142/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[143/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[144/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[145/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "[146/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313811540605 | Test Loss: 0.19942155394554137\n",
      "[147/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631295681 | Test Loss: 0.19942155394554137\n",
      "[148/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314989328385 | Test Loss: 0.19942155394554137\n",
      "[149/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313382387163 | Test Loss: 0.19942155394554137\n",
      "==> Resetting learning rate\n",
      "[150/300]: Train Acc: 38.416 | Test Acc: 10.0 | Train Loss: 0.04505165474534035 | Test Loss: 0.06040982394218445\n",
      "[151/300]: Train Acc: 50.32 | Test Acc: 10.0 | Train Loss: 0.028086332781314848 | Test Loss: 0.05981518533825874\n",
      "[152/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028281740869879723 | Test Loss: 0.05977273435592651\n",
      "[153/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284538444280624 | Test Loss: 0.05977060098648071\n",
      "[154/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284388217926025 | Test Loss: 0.05977051015496254\n",
      "[155/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437126159668 | Test Loss: 0.05977051220536232\n",
      "[156/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437073588371 | Test Loss: 0.05977051220536232\n",
      "[157/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370563030244 | Test Loss: 0.05977051187157631\n",
      "[158/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370549321175 | Test Loss: 0.05977051387429237\n",
      "[159/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371222257614 | Test Loss: 0.05977051220536232\n",
      "[160/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370592832564 | Test Loss: 0.05977051220536232\n",
      "[161/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370852708816 | Test Loss: 0.05977051220536232\n",
      "[162/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370728731155 | Test Loss: 0.05977051220536232\n",
      "[163/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437107205391 | Test Loss: 0.05977051220536232\n",
      "[164/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437059879303 | Test Loss: 0.05977051220536232\n",
      "[165/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437108039856 | Test Loss: 0.05977051220536232\n",
      "[166/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437064290047 | Test Loss: 0.05977051220536232\n",
      "[167/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370765089988 | Test Loss: 0.05977051220536232\n",
      "[168/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370560646057 | Test Loss: 0.05977051220536232\n",
      "[169/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370869994163 | Test Loss: 0.05977051220536232\n",
      "[170/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370446801186 | Test Loss: 0.05977051220536232\n",
      "[171/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370397925376 | Test Loss: 0.05977051220536232\n",
      "[172/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370869994163 | Test Loss: 0.05977051220536232\n",
      "[173/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370446801186 | Test Loss: 0.05977051220536232\n",
      "[174/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370500445365 | Test Loss: 0.05977051220536232\n",
      "[175/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370869994163 | Test Loss: 0.05977051220536232\n",
      "[176/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370365142822 | Test Loss: 0.05977051220536232\n",
      "[177/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370576143265 | Test Loss: 0.05977051387429237\n",
      "[178/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370655417442 | Test Loss: 0.05977051220536232\n",
      "[179/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370867013933 | Test Loss: 0.05977051187157631\n",
      "[180/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370386600494 | Test Loss: 0.05977051220536232\n",
      "[181/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370499849318 | Test Loss: 0.05977051187157631\n",
      "[182/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370272755623 | Test Loss: 0.05977051220536232\n",
      "[183/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370077252388 | Test Loss: 0.05977051220536232\n",
      "[184/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370945692063 | Test Loss: 0.05977051220536232\n",
      "[185/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370422959327 | Test Loss: 0.05977051220536232\n",
      "[186/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370411634445 | Test Loss: 0.05977051387429237\n",
      "[187/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370598196985 | Test Loss: 0.05977051220536232\n",
      "[188/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370084404944 | Test Loss: 0.05977051220536232\n",
      "[189/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370945692063 | Test Loss: 0.05977051220536232\n",
      "[190/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437025129795 | Test Loss: 0.05977051220536232\n",
      "[191/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370411634445 | Test Loss: 0.05977051220536232\n",
      "[192/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370477199554 | Test Loss: 0.05977051387429237\n",
      "[193/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437039077282 | Test Loss: 0.05977051220536232\n",
      "[194/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370153546335 | Test Loss: 0.05977051220536232\n",
      "[195/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437072098255 | Test Loss: 0.05977051220536232\n",
      "[196/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437051475048 | Test Loss: 0.05977051220536232\n",
      "[197/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370465278624 | Test Loss: 0.05977051387429237\n",
      "[198/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370790719986 | Test Loss: 0.05977051220536232\n",
      "[199/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[200/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[201/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[202/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[203/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[204/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[205/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[206/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[207/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[208/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[209/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[210/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[211/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[212/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[213/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[214/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[215/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[216/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[217/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[218/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[219/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[220/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[221/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[222/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[223/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[224/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[225/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[226/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[227/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[228/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[229/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[230/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[231/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[232/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[233/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[234/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[235/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[236/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[237/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[238/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[239/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[240/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[241/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[242/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[243/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[244/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[245/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[246/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[247/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "[248/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369999170302 | Test Loss: 0.05977051220536232\n",
      "[249/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284369883537292 | Test Loss: 0.05977051220536232\n",
      "==> Resetting learning rate\n",
      "[250/300]: Train Acc: 7.696 | Test Acc: 10.0 | Train Loss: 0.044804405875205996 | Test Loss: 0.03891768615245819\n",
      "[251/300]: Train Acc: 5.648 | Test Acc: 10.0 | Train Loss: 0.0381636430644989 | Test Loss: 0.03719785677194595\n",
      "[252/300]: Train Acc: 3.728 | Test Acc: 10.0 | Train Loss: 0.03728373770713806 | Test Loss: 0.03677169818878174\n",
      "[253/300]: Train Acc: 2.704 | Test Acc: 10.0 | Train Loss: 0.0370261309838295 | Test Loss: 0.036624437260627744\n",
      "[254/300]: Train Acc: 1.936 | Test Acc: 10.0 | Train Loss: 0.03693037474155426 | Test Loss: 0.03656561629772186\n",
      "[255/300]: Train Acc: 1.424 | Test Acc: 10.0 | Train Loss: 0.03689074084758759 | Test Loss: 0.036540438854694365\n",
      "[256/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03687347681999206 | Test Loss: 0.03652929005622864\n",
      "[257/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036865772752761844 | Test Loss: 0.03652428088188171\n",
      "[258/300]: Train Acc: 1.168 | Test Acc: 10.0 | Train Loss: 0.03686229662418365 | Test Loss: 0.036522010922431944\n",
      "[259/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03686072142124176 | Test Loss: 0.03652097424268722\n",
      "[260/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036860004243850705 | Test Loss: 0.03652051084041595\n",
      "[261/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.0368596781873703 | Test Loss: 0.03652030048370361\n",
      "[262/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685953006267548 | Test Loss: 0.036520197534561157\n",
      "[263/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685946264743805 | Test Loss: 0.036520155334472656\n",
      "[264/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685943219661713 | Test Loss: 0.03652013725042343\n",
      "[265/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685941821575165 | Test Loss: 0.03652012071609497\n",
      "[266/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859411058425905 | Test Loss: 0.03652011914253235\n",
      "[267/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859408764839174 | Test Loss: 0.03652011861801147\n",
      "[268/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940787792206 | Test Loss: 0.03652012041807175\n",
      "[269/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859407105445864 | Test Loss: 0.03652011969089508\n",
      "[270/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406509399416 | Test Loss: 0.036520119881629946\n",
      "[271/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406385421754 | Test Loss: 0.036520119881629946\n",
      "[272/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406423568726 | Test Loss: 0.03652011765241623\n",
      "[273/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.0368594064283371 | Test Loss: 0.03652011765241623\n",
      "[274/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940659046173 | Test Loss: 0.03652011765241623\n",
      "[275/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[276/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[277/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[278/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[279/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[280/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[281/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[282/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[283/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[284/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[285/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[286/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[287/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[288/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[289/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[290/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[291/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[292/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[293/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[294/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[295/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[296/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[297/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[298/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[299/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "[300/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940641403198 | Test Loss: 0.03652011765241623\n",
      "\n",
      "==> Beginning training with seed 4 and shuffle setting {'train': False, 'test': False}\n",
      "------------------------------\n",
      "==> Building model..\n",
      "==> Loading data..\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Saving to checkpoint..\n",
      "[1/300]: Train Acc: 86.626 | Test Acc: 10.09 | Train Loss: 0.028874411865919828 | Test Loss: 0.21324798104912043\n",
      "[2/300]: Train Acc: 81.55 | Test Acc: 10.05 | Train Loss: 0.02645868608698249 | Test Loss: 0.20299250556975604\n",
      "[3/300]: Train Acc: 81.68 | Test Acc: 10.04 | Train Loss: 0.026150612516254185 | Test Loss: 0.2008892281770706\n",
      "[4/300]: Train Acc: 81.552 | Test Acc: 10.02 | Train Loss: 0.026153615406900643 | Test Loss: 0.19963257866352796\n",
      "[5/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02611818303987384 | Test Loss: 0.19939801526069642\n",
      "[6/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026108910296410322 | Test Loss: 0.1993798873901367\n",
      "[7/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610649396285415 | Test Loss: 0.19939137921333314\n",
      "[8/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026105924346148966 | Test Loss: 0.19940566940307616\n",
      "[9/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026105940453857182 | Test Loss: 0.19941603364944457\n",
      "[10/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610598368436098 | Test Loss: 0.19942357087135315\n",
      "[11/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106170210689308 | Test Loss: 0.19942683572769165\n",
      "[12/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610623764976859 | Test Loss: 0.1994282413959503\n",
      "[13/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610628503009677 | Test Loss: 0.19942874126434326\n",
      "[14/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106301951110363 | Test Loss: 0.19942895541191102\n",
      "[15/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106317207813264 | Test Loss: 0.1994289101600647\n",
      "[16/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106321493387222 | Test Loss: 0.19942893357276917\n",
      "[17/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106318682432173 | Test Loss: 0.1994289086818695\n",
      "[18/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106317410469055 | Test Loss: 0.19942889523506163\n",
      "[19/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106315969228744 | Test Loss: 0.19942886905670165\n",
      "[20/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631560087204 | Test Loss: 0.1994288688659668\n",
      "[21/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312355995177 | Test Loss: 0.1994288571357727\n",
      "[22/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313205957413 | Test Loss: 0.19942885422706605\n",
      "[23/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631222128868 | Test Loss: 0.1994288598060608\n",
      "[24/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106311345100403 | Test Loss: 0.19942885723114015\n",
      "[25/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106314345598222 | Test Loss: 0.199428857088089\n",
      "[26/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106313492059708 | Test Loss: 0.19942886142730712\n",
      "[27/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631256222725 | Test Loss: 0.19942886428833007\n",
      "[28/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310855150222 | Test Loss: 0.19942886590957642\n",
      "[29/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106316962242127 | Test Loss: 0.1994288556575775\n",
      "[30/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106316418647767 | Test Loss: 0.1994288556575775\n",
      "[31/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631227374077 | Test Loss: 0.1994288613319397\n",
      "[32/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631106853485 | Test Loss: 0.1994288586616516\n",
      "[33/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631662964821 | Test Loss: 0.199428857088089\n",
      "[34/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631167650223 | Test Loss: 0.1994288643836975\n",
      "[35/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[36/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[37/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[38/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[39/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[40/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[41/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[42/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[43/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[44/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[45/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[46/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[47/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[49/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[50/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[51/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[52/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[53/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[54/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[55/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[56/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[57/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[58/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[59/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[60/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[61/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[62/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[63/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[64/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[65/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[66/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[67/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[68/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[69/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[70/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[71/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[72/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[73/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[74/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[75/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[76/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[77/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[78/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[79/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[80/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[81/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[82/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[83/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[84/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[85/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[86/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[87/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[88/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[89/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[90/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[91/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[92/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[93/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[94/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[95/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[96/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[97/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[98/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[99/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[100/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[101/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[102/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[103/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[104/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[105/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[106/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[107/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[108/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[109/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[110/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[111/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[112/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[113/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[114/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[115/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[116/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[117/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[118/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[119/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[120/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[121/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[123/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[124/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[125/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[126/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[127/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[128/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[129/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[130/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[131/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[132/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[133/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[134/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[135/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[136/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[137/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[138/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[139/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[140/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[141/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[142/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "[143/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631098985672 | Test Loss: 0.19942885723114015\n",
      "[144/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106310625076293 | Test Loss: 0.1994288571357727\n",
      "[145/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631688952446 | Test Loss: 0.199428857088089\n",
      "[146/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.0261063116812706 | Test Loss: 0.1994288643836975\n",
      "[147/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312857866288 | Test Loss: 0.199428865814209\n",
      "[148/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.02610631676197052 | Test Loss: 0.1994288556575775\n",
      "[149/300]: Train Acc: 81.424 | Test Acc: 10.0 | Train Loss: 0.026106312314271927 | Test Loss: 0.1994288598060608\n",
      "==> Resetting learning rate\n",
      "[150/300]: Train Acc: 38.416 | Test Acc: 10.0 | Train Loss: 0.04505166676819324 | Test Loss: 0.06037244443297386\n",
      "[151/300]: Train Acc: 50.32 | Test Acc: 10.0 | Train Loss: 0.028086332061886786 | Test Loss: 0.059769362330436705\n",
      "[152/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828174109518528 | Test Loss: 0.05972683993577957\n",
      "[153/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282845387250185 | Test Loss: 0.0597247256398201\n",
      "[154/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284387990236283 | Test Loss: 0.059724640041589734\n",
      "[155/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370953440666 | Test Loss: 0.059724641543626784\n",
      "[156/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371339678763 | Test Loss: 0.05972464237809181\n",
      "[157/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437057852745 | Test Loss: 0.05972464237809181\n",
      "[158/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284371205568315 | Test Loss: 0.05972464235424996\n",
      "[159/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370708465578 | Test Loss: 0.05972464235424996\n",
      "[160/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437088251114 | Test Loss: 0.05972464235424996\n",
      "[161/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370322227477 | Test Loss: 0.05972464237809181\n",
      "[162/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437100112438 | Test Loss: 0.05972464235424996\n",
      "[163/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437081515789 | Test Loss: 0.05972464237809181\n",
      "[164/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437026619911 | Test Loss: 0.05972464225888252\n",
      "[165/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370730519294 | Test Loss: 0.05972464235424996\n",
      "[166/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370579123495 | Test Loss: 0.05972464237809181\n",
      "[167/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370046257973 | Test Loss: 0.059724641638994214\n",
      "[168/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.02828437080979347 | Test Loss: 0.05972464235424996\n",
      "[169/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370849132538 | Test Loss: 0.05972464237809181\n",
      "[170/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370007514954 | Test Loss: 0.05972464237809181\n",
      "[171/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370210170745 | Test Loss: 0.05972464225888252\n",
      "[172/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370867013933 | Test Loss: 0.05972464235424996\n",
      "[173/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370830655096 | Test Loss: 0.05972464237809181\n",
      "[174/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370054602624 | Test Loss: 0.05972464237809181\n",
      "[175/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370942711832 | Test Loss: 0.05972464235424996\n",
      "[176/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370890259744 | Test Loss: 0.05972464237809181\n",
      "[177/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370054602624 | Test Loss: 0.05972464237809181\n",
      "[178/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370942711832 | Test Loss: 0.05972464235424996\n",
      "[179/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370899796487 | Test Loss: 0.05972464237809181\n",
      "[180/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.028284370048046112 | Test Loss: 0.05972464237809181\n",
      "[181/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[182/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[183/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[184/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[185/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[186/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[187/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[188/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[189/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[190/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[191/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[192/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[193/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[194/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[195/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[196/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[197/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[198/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[199/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[200/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[201/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[202/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[203/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[204/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[205/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[206/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[207/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[208/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[209/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[210/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[211/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[212/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[213/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[214/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[215/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[216/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[217/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[218/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[219/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[220/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[221/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[222/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[223/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[224/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[225/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[226/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[227/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[228/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[229/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[230/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[231/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[232/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[233/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[234/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[235/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[236/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[237/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[238/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[239/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[240/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[241/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[242/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[243/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[244/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[245/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[246/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[247/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[248/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "[249/300]: Train Acc: 50.064 | Test Acc: 10.0 | Train Loss: 0.0282843699580431 | Test Loss: 0.05972464237809181\n",
      "==> Resetting learning rate\n",
      "[250/300]: Train Acc: 7.696 | Test Acc: 10.0 | Train Loss: 0.04480440559387207 | Test Loss: 0.038882531726360324\n",
      "[251/300]: Train Acc: 5.648 | Test Acc: 10.0 | Train Loss: 0.03816364333152771 | Test Loss: 0.03717178536653519\n",
      "[252/300]: Train Acc: 3.728 | Test Acc: 10.0 | Train Loss: 0.03728373794078827 | Test Loss: 0.03675035328865051\n",
      "[253/300]: Train Acc: 2.704 | Test Acc: 10.0 | Train Loss: 0.037026130740642545 | Test Loss: 0.03660535910129547\n",
      "[254/300]: Train Acc: 1.936 | Test Acc: 10.0 | Train Loss: 0.036930374884605405 | Test Loss: 0.036547601151466366\n",
      "[255/300]: Train Acc: 1.424 | Test Acc: 10.0 | Train Loss: 0.03689074077606201 | Test Loss: 0.0365229150891304\n",
      "[256/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036873477144241336 | Test Loss: 0.03651199264526367\n",
      "[257/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03686577244281769 | Test Loss: 0.03650708911418915\n",
      "[258/300]: Train Acc: 1.168 | Test Acc: 10.0 | Train Loss: 0.036862296433448793 | Test Loss: 0.03650486767292023\n",
      "[259/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03686072145462036 | Test Loss: 0.03650385776758194\n",
      "[260/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036860004529953 | Test Loss: 0.03650339977741241\n",
      "[261/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859678301811215 | Test Loss: 0.03650319654941559\n",
      "[262/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685952982902527 | Test Loss: 0.03650309545993805\n",
      "[263/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859462580680846 | Test Loss: 0.03650305542945862\n",
      "[264/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859432115554806 | Test Loss: 0.03650303244590759\n",
      "[265/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685941825389862 | Test Loss: 0.03650301911830902\n",
      "[266/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859411373138425 | Test Loss: 0.03650301802158356\n",
      "[267/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940899848938 | Test Loss: 0.03650301643610001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[268/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940800666809 | Test Loss: 0.03650301643610001\n",
      "[269/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940691947937 | Test Loss: 0.036503018927574155\n",
      "[270/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940675735474 | Test Loss: 0.03650301641225815\n",
      "[271/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406509399416 | Test Loss: 0.03650301605463028\n",
      "[272/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940639019013 | Test Loss: 0.03650301659107208\n",
      "[273/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406361579895 | Test Loss: 0.036503016233444215\n",
      "[274/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940639019013 | Test Loss: 0.03650301659107208\n",
      "[275/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940637588501 | Test Loss: 0.03650301659107208\n",
      "[276/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940634727478 | Test Loss: 0.03650301659107208\n",
      "[277/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.03685940630435944 | Test Loss: 0.03650301659107208\n",
      "[278/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[279/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[280/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[281/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[282/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[283/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[284/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[285/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[286/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[287/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[288/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[289/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[290/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[291/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[292/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[293/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[294/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[295/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[296/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[297/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[298/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[299/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "[300/300]: Train Acc: 1.296 | Test Acc: 10.0 | Train Loss: 0.036859406180381776 | Test Loss: 0.03650301659107208\n",
      "39002.4266706\n"
     ]
    }
   ],
   "source": [
    "resume = False\n",
    "given_date = '20191113'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "### task: classification of the following classes\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    \n",
    "### hyperparameters\n",
    "test_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "num_epochs = 300 # number of iterations the model gets trained\n",
    "learning_rate = 0.1 # factor for weight updates\n",
    "learning_rate_switches = { # learning rate is reset after specific epochs\n",
    "    '150': 0.01,\n",
    "    '250': 0.001\n",
    "}\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "rows = []\n",
    "for seed in SEEDS:\n",
    "    for shuffle_setting in [{'train': False, 'test': False}]:#, {'train': True, 'test': True}]:\n",
    "        print(\"\\n==> Beginning training with seed {} and shuffle setting {}\".format(seed, shuffle_setting))\n",
    "        print(\"-\" * 30)\n",
    "        torch.manual_seed(seed)\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "             \n",
    "        ### Model\n",
    "        print('==> Building model..')\n",
    "        net = ResNet18()\n",
    "        net = net.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "        \n",
    "        ### load the data\n",
    "        # if needed, specify batch sizes and shuffle settings\n",
    "        print('==> Loading data..')\n",
    "        dataloader = DataLoader()\n",
    "        dataloader.download_cifar()\n",
    "        dataloader.prepare_cifar('homogeneous', random_state=seed, batch_size=64)\n",
    "\n",
    "        if resume:\n",
    "            print('==> Resuming from checkpoint..')\n",
    "            assert os.path.isdir('serialized'), 'Error: no serialized directory found!'\n",
    "            ckpt = torch.load('./serialized/{}/ckpt_{}.pth'.format(given_date, seed))\n",
    "            test_acc, start_epoch, net = net.load(ckpt)\n",
    "\n",
    "        for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "            if str(epoch+1) in learning_rate_switches.keys():\n",
    "                print('==> Resetting learning rate')\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = learning_rate_switches[str(epoch+1)]\n",
    "                    \n",
    "            train_acc, train_loss = train(epoch, optimizer, criterion, dataloader)\n",
    "            test_acc, test_loss = test(epoch, test_acc, seed, dataloader)\n",
    "            print(\"[{}/{}]: Train Acc: {} | Test Acc: {} | Train Loss: {} | Test Loss: {}\"\\\n",
    "                  .format(epoch+1, num_epochs, train_acc, test_acc, train_loss, test_loss))\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'seed': seed,\n",
    "                'train': True,\n",
    "                'shuffle': True if shuffle_setting['train'] == True else False,\n",
    "                'accuracy': train_acc,\n",
    "                'loss': train_loss\n",
    "            }\n",
    "            rows.append(row)\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'seed': seed,\n",
    "                'train': False,\n",
    "                'shuffle': True if shuffle_setting['train'] == True else False,\n",
    "                'accuracy': test_acc,\n",
    "                'loss': test_loss\n",
    "            }\n",
    "            rows.append(row)\n",
    "            \n",
    "stop = timeit.default_timer()\n",
    "logging_df = pd.DataFrame(rows, columns=['epoch', 'seed', 'train', 'shuffle', 'accuracy', 'loss'])   \n",
    "training_logs_dir = 'training_logs'\n",
    "logging_df.to_csv('{}.txt'.format(os.path.join(training_logs_dir, today)), sep='\\t', index=False)\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False\n",
    "given_date = '20191113'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "### task: classification of the following classes\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    \n",
    "### hyperparameters\n",
    "test_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "num_epochs = 300 # number of iterations the model gets trained\n",
    "learning_rate = 0.1 # factor for weight updates\n",
    "learning_rate_switches = { # learning rate is reset after specific epochs\n",
    "    '150': 0.01,\n",
    "    '250': 0.001\n",
    "}\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "rows = []\n",
    "for seed in SEEDS:\n",
    "    for shuffle_setting in [{'train': False, 'test': False}]:#, {'train': True, 'test': True}]:\n",
    "        print(\"\\n==> Beginning training with seed {} and shuffle setting {}\".format(seed, shuffle_setting))\n",
    "        print(\"-\" * 30)\n",
    "        torch.manual_seed(seed)\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "             \n",
    "        ### Model\n",
    "        print('==> Building model..')\n",
    "        net = ResNet18()\n",
    "        net = net.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "        \n",
    "        ### load the data\n",
    "        # if needed, specify batch sizes and shuffle settings\n",
    "        print('==> Loading data..')\n",
    "        dataloader = DataLoader()\n",
    "        dataloader.download_cifar()\n",
    "        dataloader.prepare_cifar('homogeneous', random_state=seed, batch_size=64)\n",
    "\n",
    "        if resume:\n",
    "            print('==> Resuming from checkpoint..')\n",
    "            assert os.path.isdir('serialized'), 'Error: no serialized directory found!'\n",
    "            ckpt = torch.load('./serialized/{}/ckpt_{}.pth'.format(given_date, seed))\n",
    "            test_acc, start_epoch, net = net.load(ckpt)\n",
    "\n",
    "        for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "            if str(epoch+1) in learning_rate_switches.keys():\n",
    "                print('==> Resetting learning rate')\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = learning_rate_switches[str(epoch+1)]\n",
    "                    \n",
    "            train_acc, train_loss = train(epoch, optimizer, criterion, dataloader)\n",
    "            test_acc, test_loss = test(epoch, test_acc, seed, dataloader)\n",
    "            print(\"[{}/{}]: Train Acc: {} | Test Acc: {} | Train Loss: {} | Test Loss: {}\"\\\n",
    "                  .format(epoch+1, num_epochs, train_acc, test_acc, train_loss, test_loss))\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'seed': seed,\n",
    "                'train': True,\n",
    "                'shuffle': True if shuffle_setting['train'] == True else False,\n",
    "                'accuracy': train_acc,\n",
    "                'loss': train_loss\n",
    "            }\n",
    "            rows.append(row)\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'seed': seed,\n",
    "                'train': False,\n",
    "                'shuffle': True if shuffle_setting['train'] == True else False,\n",
    "                'accuracy': test_acc,\n",
    "                'loss': test_loss\n",
    "            }\n",
    "            rows.append(row)\n",
    "            \n",
    "stop = timeit.default_timer()\n",
    "logging_df = pd.DataFrame(rows, columns=['epoch', 'seed', 'train', 'shuffle', 'accuracy', 'loss'])   \n",
    "training_logs_dir = 'training_logs'\n",
    "logging_df.to_csv('{}.txt'.format(os.path.join(training_logs_dir, today)), sep='\\t', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
