{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Intelligence with Deep Learning\n",
    "## Importance batching for improved training of neural networks\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import ResNet18\n",
    "from utils.data_utils import DataLoader\n",
    "from utils.logging_utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "today = datetime.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [10]\n",
    "STRATEGIES = ['shuffle']\n",
    "\n",
    "#SEEDS = [10, 42, 4] # don't change!\n",
    "#STRATEGIES = ['freeze', 'shuffle', 'homogeneous', 'heterogeneous'] # can be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training\n",
    "def train(epoch, optimizer, criterion, dataloader):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader.yield_batches(use_train=True)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    train_acc = 100.*correct/total\n",
    "    train_loss /= total\n",
    "    return train_acc, train_loss\n",
    "\n",
    "### Testing\n",
    "def test(epoch, best_acc, seed, dataloader):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader.yield_batches(use_train=False)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    test_acc = 100.*correct/total\n",
    "    test_loss /= total\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        net.save(best_acc, epoch, seed, strategy)\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| Seeds: [10]                                                                            |\n",
      "| Strategies: ['shuffle']                                                                |\n",
      "| -> Resulting number of iterations: 1                                                   |\n",
      "| Number of iterations: 150                                                              |\n",
      "| Learning rates: {'1': 0.1, '50': 0.01, '100': 0.001}                                   |\n",
      "| Resuming from checkpoint: False                                                        |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| Seed: 10      Strategy: shuffle                                                         |\n",
      "| Epoch         Train Accuracy  Test Accuracy   Train Loss   Test Loss                   |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "| [001/150]:    31.06           041.1           0.02987      0.02604                     |\n",
      "| [002/150]:    47.86           042.9           0.02215      0.02734                     |\n",
      "| [003/150]:    59.74           59.47           0.01761      0.02023                     |\n",
      "| [004/150]:    68.19           69.77           00.0141      0.01356                     |\n",
      "| [005/150]:    74.15           071.3           0.01168      0.01393                     |\n",
      "| [006/150]:    77.31           73.56           0.01023      0.01259                     |\n",
      "| [007/150]:    79.31           76.49           0.00935      0.01114                     |\n",
      "| [008/150]:    80.71           73.25           0.00873      0.01309                     |\n",
      "| [009/150]:    81.88           71.77           0.00812      0.01415                     |\n",
      "| [010/150]:    82.71           70.54           0.00772      0.01612                     |\n",
      "| [011/150]:    83.32           72.99           0.00738      0.01386                     |\n",
      "| [012/150]:    83.99           74.48           0.00718      0.01358                     |\n",
      "| [013/150]:    84.55           73.76           0.00693      00.0139                     |\n",
      "| [014/150]:    85.01           71.83           0.00675      0.01484                     |\n",
      "| [015/150]:    85.21           75.89           0.00667      0.01245                     |\n",
      "| [016/150]:    85.43           77.11           0.00651      0.01256                     |\n",
      "| [017/150]:    86.03           74.48           0.00632      00.0137                     |\n",
      "| [018/150]:    85.99           76.39           0.00634      0.01289                     |\n",
      "| [019/150]:    86.23           075.7           0.00624      0.01323                     |\n",
      "| [020/150]:    86.35           75.63           0.00614      0.01282                     |\n",
      "| [021/150]:    86.58           75.54           0.00607      0.01247                     |\n",
      "| [022/150]:    86.22           68.88           0.00615      0.01893                     |\n",
      "| [023/150]:    86.52           73.65           0.00606      0.01473                     |\n",
      "| [024/150]:    86.54           75.54           0.00602      0.01341                     |\n",
      "| [025/150]:    86.57           75.77           0.00604      0.01273                     |\n",
      "| [026/150]:    086.8           75.57           0.00598      0.01339                     |\n",
      "| [027/150]:    86.87           075.8           0.00589      0.01331                     |\n",
      "| [028/150]:    86.77           63.84           0.00595      0.02686                     |\n",
      "| [029/150]:    86.97           075.1           0.00587      0.01304                     |\n",
      "| [030/150]:    86.96           72.89           0.00585      0.01821                     |\n",
      "| [031/150]:    86.99           68.24           0.00583      0.01741                     |\n",
      "| [032/150]:    87.09           77.52           0.00578      0.01278                     |\n",
      "| [033/150]:    87.24           71.73           0.00577      0.01753                     |\n",
      "| [034/150]:    87.14           72.59           0.00577      0.01565                     |\n",
      "| [035/150]:    87.28           74.19           0.00572      0.01441                     |\n",
      "| [036/150]:    87.21           75.39           0.00577      0.01355                     |\n",
      "| [037/150]:    87.13           72.75           0.00581      0.01603                     |\n",
      "| [038/150]:    087.1           74.52           0.00579      0.01458                     |\n",
      "| [039/150]:    87.35           77.17           0.00567      00.0129                     |\n",
      "| [040/150]:    087.5           74.56           0.00567      0.01421                     |\n",
      "| [041/150]:    87.65           72.48           0.00565      0.01646                     |\n",
      "| [042/150]:    87.21           74.89           0.00574      0.01439                     |\n",
      "| [043/150]:    87.22           73.38           0.00572      00.0157                     |\n",
      "| [044/150]:    87.19           75.38           0.00573      00.0134                     |\n",
      "| [045/150]:    87.55           75.28           0.00565      0.01414                     |\n",
      "| [046/150]:    87.64           70.77           0.00561      0.01695                     |\n",
      "| [047/150]:    87.39           77.02           0.00567      0.01203                     |\n",
      "| [048/150]:    87.48           76.04           0.00563      0.01303                     |\n",
      "| [049/150]:    87.67           72.91           0.00562      0.01626                     |\n",
      "| [050/150]:    94.82           85.99           0.00246      0.00724                     |\n",
      "| [051/150]:    99.21           86.07           0.00059      0.00777                     |\n",
      "| [052/150]:    99.91           86.05           0.00019      0.00802                     |\n",
      "| [053/150]:    99.97           86.11           00.0001      00.0081                     |\n",
      "| [054/150]:    99.98           86.15           008e-05      00.0081                     |\n",
      "| [055/150]:    100.0           86.14           006e-05      0.00807                     |\n",
      "| [056/150]:    100.0           086.1           006e-05      0.00801                     |\n",
      "| [057/150]:    100.0           086.2           005e-05      0.00795                     |\n",
      "| [058/150]:    100.0           86.23           005e-05      0.00789                     |\n",
      "| [059/150]:    100.0           86.25           005e-05      0.00783                     |\n",
      "| [060/150]:    100.0           86.36           005e-05      0.00777                     |\n",
      "| [061/150]:    100.0           86.36           004e-05      0.00772                     |\n",
      "| [062/150]:    100.0           86.43           004e-05      0.00767                     |\n",
      "| [063/150]:    100.0           86.39           004e-05      0.00763                     |\n",
      "| [064/150]:    100.0           86.41           004e-05      0.00758                     |\n",
      "| [065/150]:    100.0           86.37           004e-05      0.00754                     |\n",
      "| [066/150]:    100.0           86.41           004e-05      00.0075                     |\n",
      "| [067/150]:    100.0           86.37           004e-05      0.00747                     |\n",
      "| [068/150]:    100.0           86.43           004e-05      0.00743                     |\n",
      "| [069/150]:    100.0           086.4           004e-05      0.00741                     |\n",
      "| [070/150]:    100.0           86.44           003e-05      0.00738                     |\n",
      "| [071/150]:    100.0           86.47           003e-05      0.00736                     |\n",
      "| [072/150]:    100.0           86.43           003e-05      0.00734                     |\n",
      "| [073/150]:    100.0           86.41           003e-05      0.00733                     |\n",
      "| [074/150]:    100.0           86.41           003e-05      0.00732                     |\n",
      "| [075/150]:    100.0           86.41           003e-05      0.00731                     |\n",
      "| [076/150]:    100.0           86.31           003e-05      0.00731                     |\n",
      "| [077/150]:    100.0           086.3           003e-05      0.00731                     |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| [078/150]:    100.0           86.29           003e-05      0.00731                     |\n",
      "| [079/150]:    100.0           86.26           003e-05      0.00731                     |\n",
      "| [080/150]:    100.0           86.25           003e-05      0.00733                     |\n",
      "| [081/150]:    100.0           86.17           003e-05      0.00734                     |\n",
      "| [082/150]:    100.0           86.17           003e-05      0.00736                     |\n",
      "| [083/150]:    100.0           86.25           003e-05      0.00738                     |\n",
      "| [084/150]:    100.0           86.19           003e-05      0.00741                     |\n",
      "| [085/150]:    100.0           86.13           003e-05      0.00744                     |\n",
      "| [086/150]:    100.0           86.22           003e-05      0.00747                     |\n",
      "| [087/150]:    100.0           86.25           003e-05      00.0075                     |\n",
      "| [088/150]:    100.0           86.22           003e-05      0.00753                     |\n",
      "| [089/150]:    100.0           86.25           003e-05      0.00757                     |\n",
      "| [090/150]:    100.0           86.27           003e-05      00.0076                     |\n",
      "| [091/150]:    100.0           86.16           003e-05      0.00764                     |\n",
      "| [092/150]:    100.0           86.08           003e-05      0.00767                     |\n",
      "| [093/150]:    100.0           86.04           003e-05      0.00771                     |\n",
      "| [094/150]:    100.0           86.01           003e-05      0.00775                     |\n",
      "| [095/150]:    100.0           85.99           003e-05      0.00779                     |\n",
      "| [096/150]:    100.0           85.98           003e-05      0.00784                     |\n",
      "| [097/150]:    100.0           85.92           003e-05      0.00788                     |\n",
      "| [098/150]:    100.0           85.88           003e-05      0.00793                     |\n",
      "| [099/150]:    100.0           85.86           003e-05      0.00796                     |\n",
      "| [100/150]:    100.0           086.2           002e-05      0.00793                     |\n",
      "| [101/150]:    100.0           086.2           002e-05      0.00794                     |\n",
      "| [102/150]:    100.0           86.18           002e-05      0.00794                     |\n",
      "| [103/150]:    100.0           86.19           002e-05      0.00795                     |\n",
      "| [104/150]:    100.0           86.17           002e-05      0.00795                     |\n",
      "| [105/150]:    100.0           86.16           002e-05      0.00796                     |\n",
      "| [106/150]:    100.0           86.14           002e-05      0.00796                     |\n",
      "| [107/150]:    100.0           86.17           002e-05      0.00797                     |\n",
      "| [108/150]:    100.0           86.14           002e-05      0.00797                     |\n",
      "| [109/150]:    100.0           86.16           002e-05      0.00798                     |\n",
      "| [110/150]:    100.0           86.17           002e-05      0.00798                     |\n",
      "| [111/150]:    100.0           86.14           002e-05      0.00799                     |\n",
      "| [112/150]:    100.0           86.14           002e-05      000.008                     |\n",
      "| [113/150]:    100.0           86.13           002e-05      000.008                     |\n",
      "| [114/150]:    100.0           86.13           002e-05      0.00801                     |\n",
      "| [115/150]:    100.0           86.12           002e-05      0.00801                     |\n",
      "| [116/150]:    100.0           86.12           002e-05      0.00802                     |\n",
      "| [117/150]:    100.0           86.16           002e-05      0.00802                     |\n",
      "| [118/150]:    100.0           86.16           002e-05      0.00803                     |\n",
      "| [119/150]:    100.0           86.16           002e-05      0.00804                     |\n",
      "| [120/150]:    100.0           86.17           002e-05      0.00804                     |\n",
      "| [121/150]:    100.0           86.18           002e-05      0.00805                     |\n",
      "| [122/150]:    100.0           86.13           002e-05      0.00805                     |\n",
      "| [123/150]:    100.0           86.14           002e-05      0.00806                     |\n",
      "| [124/150]:    100.0           86.13           002e-05      0.00806                     |\n",
      "| [125/150]:    100.0           86.14           002e-05      0.00807                     |\n",
      "| [126/150]:    100.0           86.16           002e-05      0.00808                     |\n",
      "| [127/150]:    100.0           86.17           002e-05      0.00809                     |\n",
      "| [128/150]:    100.0           86.21           002e-05      0.00809                     |\n",
      "| [129/150]:    100.0           086.2           002e-05      00.0081                     |\n",
      "| [130/150]:    100.0           086.2           002e-05      0.00811                     |\n",
      "| [131/150]:    100.0           86.13           002e-05      0.00811                     |\n",
      "| [132/150]:    100.0           86.12           002e-05      0.00812                     |\n",
      "| [133/150]:    100.0           86.15           002e-05      0.00813                     |\n",
      "| [134/150]:    100.0           86.15           002e-05      0.00814                     |\n",
      "| [135/150]:    100.0           86.14           002e-05      0.00814                     |\n",
      "| [136/150]:    100.0           86.17           002e-05      0.00815                     |\n",
      "| [137/150]:    100.0           086.2           002e-05      0.00816                     |\n",
      "| [138/150]:    100.0           86.16           002e-05      0.00816                     |\n",
      "| [139/150]:    100.0           86.16           002e-05      0.00817                     |\n",
      "| [140/150]:    100.0           86.15           002e-05      0.00818                     |\n",
      "| [141/150]:    100.0           86.16           002e-05      0.00819                     |\n",
      "| [142/150]:    100.0           086.2           002e-05      00.0082                     |\n",
      "| [143/150]:    100.0           86.23           002e-05      00.0082                     |\n",
      "| [144/150]:    100.0           086.2           002e-05      0.00821                     |\n",
      "| [145/150]:    100.0           86.18           002e-05      0.00822                     |\n",
      "| [146/150]:    100.0           086.2           002e-05      0.00823                     |\n",
      "| [147/150]:    100.0           86.22           002e-05      0.00824                     |\n",
      "| [148/150]:    100.0           086.2           002e-05      0.00825                     |\n",
      "| [149/150]:    100.0           86.22           002e-05      0.00826                     |\n",
      "| [150/150]:    100.0           086.2           002e-05      0.00826                     |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "\n",
      "Finished training. Time needed: 1 hrs 49 mins 22 secs\n"
     ]
    }
   ],
   "source": [
    "resume = False\n",
    "given_date = '20191113'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "### task: classification of the following classes\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    \n",
    "### hyperparameters\n",
    "test_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "num_epochs = 150 # number of iterations the model gets trained\n",
    "learning_rates = { # learning rate is reset after specific epochs\n",
    "    '1': 0.1,\n",
    "    '50': 0.01,\n",
    "    '100': 0.001\n",
    "}\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "print(\"Begin training.\")\n",
    "start = timeit.default_timer()\n",
    "#Logging header\n",
    "length_table = 90\n",
    "log_separating_line(length_table)\n",
    "log_header_line(\"Seeds: {}\".format(SEEDS), length_table)\n",
    "log_header_line(\"Strategies: {}\".format(STRATEGIES), length_table)\n",
    "log_header_line(\"-> Resulting number of iterations: {}\".format(len(SEEDS) * len(STRATEGIES)), length_table)\n",
    "log_header_line(\"Number of iterations: {}\".format(num_epochs), length_table)\n",
    "log_header_line(\"Learning rates: {}\".format(learning_rates), length_table)\n",
    "log_header_line(\"Resuming from checkpoint: {}\".format(True if resume else False), length_table)\n",
    "log_separating_line(length_table)\n",
    "\n",
    "rows = []\n",
    "for seed in SEEDS:\n",
    "    for strategy in STRATEGIES:\n",
    "                \n",
    "        torch.manual_seed(seed)\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "             \n",
    "        ### Model\n",
    "        net = ResNet18()\n",
    "        net = net.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rates['1'], momentum=momentum, weight_decay=weight_decay)\n",
    "        \n",
    "        ### load the data\n",
    "        # if needed, specify batch sizes and shuffle settings\n",
    "        dataloader = DataLoader()\n",
    "        dataloader.download_cifar()\n",
    "        dataloader.prepare_cifar(strategy, random_state=seed, batch_size=64)\n",
    "        print()\n",
    "        log_separating_line(length_table)\n",
    "        log_position_header(seed, strategy, length_table)\n",
    "        log_separating_line(length_table)\n",
    "\n",
    "        if resume:\n",
    "            assert os.path.isdir('serialized'), 'Error: no serialized directory found!'\n",
    "            ckpt = torch.load('./serialized/{}/{}_ckpt_{}.pth'.format(given_date, strategy, seed))\n",
    "            test_acc, start_epoch, net = net.load(ckpt)\n",
    "\n",
    "        for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "            # reset learning rate at specific epochs\n",
    "            if str(epoch+1) in learning_rates.keys():\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = learning_rates[str(epoch+1)]\n",
    "                    \n",
    "            train_acc, train_loss = train(epoch, optimizer, criterion, dataloader)\n",
    "            test_acc, test_loss = test(epoch, test_acc, seed, dataloader)\n",
    "            log_position_line(epoch + 1, num_epochs, train_acc, test_acc, train_loss, test_loss, length_table)\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'seed': seed,\n",
    "                'train': True,\n",
    "                'strategy': strategy,\n",
    "                'accuracy': train_acc,\n",
    "                'loss': train_loss\n",
    "            }\n",
    "            rows.append(row)\n",
    "            row = {\n",
    "                'epoch': epoch + 1,\n",
    "                'seed': seed,\n",
    "                'train': False,\n",
    "                'strategy': strategy,\n",
    "                'accuracy': test_acc,\n",
    "                'loss': test_loss\n",
    "            }\n",
    "            rows.append(row)\n",
    "        log_separating_line(length_table)\n",
    "            \n",
    "stop = timeit.default_timer()\n",
    "time_needed = stop - start\n",
    "hrs = int(time_needed / 3600)\n",
    "mins = int((time_needed / 60) % 60)\n",
    "secs = int(time_needed % 60)\n",
    "print()\n",
    "print(\"Finished training. Time needed: {} hrs {} mins {} secs\".format(hrs, mins, secs))\n",
    "\n",
    "logging_df = pd.DataFrame(rows, columns=['epoch', 'seed', 'train', 'strategy', 'accuracy', 'loss'])   \n",
    "training_logs_dir = 'evaluation_logs'\n",
    "logging_df.to_csv('{}.txt'.format(os.path.join(training_logs_dir, today)), sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
