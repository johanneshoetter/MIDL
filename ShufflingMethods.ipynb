{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = ['abc', 'def', 'egh', 'ijk', 'lmn', 'opq', 'rst', 'ade', 'des', 'asd', 'a', 'sd', 'sda', 'e']\n",
    "test_targets = [1, 2, 1, 1, 2, 1, 2, 3, 4, 3, 1, 4, 2, 3]\n",
    "expected_output = [\n",
    "    ['abc', 'egh', 'ijk'],\n",
    "    ['def', 'lmn', 'rst'],\n",
    "    ['ade', 'asd', 'e'],\n",
    "    ['opq', 'a', 'sda'],\n",
    "    ['des', 'sd']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ideas for shuffle one class:\n",
    "- sort the list by class, take as many pairs for the batches as possible\n",
    "- build a dictionary with the classes and take batches from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_map_classes_buffer(inputs, targets):\n",
    "    '''\n",
    "    Build a dictionary which has the targets as keys and all the corresponding inputs as values\n",
    "    -- Params:\n",
    "    @inputs: input data for the model\n",
    "    @targets: desired outcome for the model given that it gets @inputs\n",
    "    -- Return: dictionary\n",
    "    '''\n",
    "    # build a dictionary to grab pairs from\n",
    "    map_classes_buffer = defaultdict(list) # stores class -> inputs pairs\n",
    "    list(map(lambda x, y: map_classes_buffer[y].append(x), inputs, targets)) #without list, the writes to the map are not commited\n",
    "    return map_classes_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shuffle_one_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2f21209b90fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mactual_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshuffle_one_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mactual_output\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mexpected_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Actual and expected outputs differ!'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shuffle_one_class' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def batches_one_class(inputs, targets, batch_size=64):\n",
    "    '''\n",
    "    Splits the data (inputs and targets) into as many homogeneous batches as possible,\n",
    "    i.e. that in as many cases as possible, the batches consist of one target only.\n",
    "    -- Params:\n",
    "    @inputs: input data for the model\n",
    "    @targets: desired outcome for the model given that it gets @inputs\n",
    "    @batch_size: number of samples per batch\n",
    "    -- Return: 2d list\n",
    "    '''\n",
    "    \n",
    "    assert len(inputs) == len(targets), 'Inputs and targets do not have the same size'\n",
    "    \n",
    "    batches = []\n",
    "    inputs_buffer = [] # store inputs that don't fit into homogeneous batches anymore\n",
    "    \n",
    "    num_batches = np.ceil(len(inputs) / batch_size)\n",
    "    map_classes_buffer = build_map_classes_buffer(inputs, targets)\n",
    "    \n",
    "    for target in map_classes_buffer.keys():\n",
    "        while len(map_classes_buffer[target]) > 0:\n",
    "            taken_inputs, retrieved_inputs = map_classes_buffer[target][:batch_size], map_classes_buffer[target][batch_size:]\n",
    "            if len(taken_inputs) < batch_size:\n",
    "                inputs_buffer.extend(taken_inputs)\n",
    "            else:\n",
    "                batches.append(taken_inputs)\n",
    "            map_classes_buffer[target] = retrieved_inputs\n",
    "            \n",
    "    while len(inputs_buffer) > 0:\n",
    "        taken_inputs, inputs_buffer = inputs_buffer[:batch_size], inputs_buffer[batch_size:]\n",
    "        batches.append(taken_inputs)\n",
    "                \n",
    "    assert len(batches) == num_batches, 'Error in implementation, number of batches is wrong!'\n",
    "    \n",
    "    return batches\n",
    "    \n",
    "    \n",
    "actual_output = shuffle_one_class(test_inputs, test_targets, batch_size=3)\n",
    "assert actual_output == expected_output, 'Actual and expected outputs differ!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_all_classes(inputs, targets):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import DataLoader\n",
    "dataloader = DataLoader(batch_sizes={'train': 64, 'test': 64}, shuffle={'train': False, 'test': False})\n",
    "dataloader.download_cifar()\n",
    "trainloader, testloader = dataloader.get_loaders()\n",
    "\n",
    "for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "    _inputs = inputs\n",
    "    _targets = targets\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
