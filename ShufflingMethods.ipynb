{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = ['abc', 'def', 'egh', 'ijk', 'lmn', 'opq', 'rst', 'ade', 'des', 'asd', 'a', 'sd', 'sda', 'e']\n",
    "test_targets = [1, 2, 1, 1, 2, 1, 2, 3, 4, 3, 4, 4, 2, 3]\n",
    "\n",
    "expected_output_one_class = \\\n",
    "(['abc','egh','ijk','def','lmn','rst','ade','asd','e','des','a','sd','opq','sda'],\n",
    " [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 1, 2])\n",
    "\n",
    "expected_output_all_classes = \\\n",
    "(['opq','sda','e','sd','ijk','rst','asd','a','egh','lmn','ade','des','abc','def'],\n",
    " [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_map_classes_buffer(inputs, targets):\n",
    "    '''\n",
    "    Build a dictionary which has the targets as keys and all the corresponding inputs as values\n",
    "    -- Params:\n",
    "    @inputs: input data for the model\n",
    "    @targets: desired outcome for the model given that it gets @inputs\n",
    "    -- Return: dictionary\n",
    "    '''\n",
    "    # build a dictionary to grab pairs from\n",
    "    map_classes_buffer = defaultdict(list) # stores class -> inputs pairs\n",
    "    list(map(lambda x, y: map_classes_buffer[y].append(x), inputs, targets)) #without list, the writes to the map are not commited\n",
    "    return map_classes_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def sort_one_class(inputs, targets, batch_size, use_shuffle=True, random_state=None):\n",
    "    '''\n",
    "    Splits the data (inputs and targets) into as many homogeneous batches as possible,\n",
    "    i.e. that in as many cases as possible, the batches consist of one target only.\n",
    "    -- Params:\n",
    "    @inputs: input data for the model\n",
    "    @targets: desired outcome for the model given that it gets @inputs\n",
    "    @batch_size: number of samples per batch\n",
    "    @use_shuffle: shuffle the data beforehand\n",
    "    -- Return: one 2d list for the inputs, one 2d list for the targets\n",
    "    '''\n",
    "    \n",
    "    assert len(inputs) == len(targets), 'Inputs and targets do not have the same size'\n",
    "    \n",
    "    if use_shuffle:        \n",
    "        inputs, targets = shuffle(inputs, targets, random_state=random_state)\n",
    "    \n",
    "    input_batches = []\n",
    "    target_batches = []\n",
    "    inputs_buffer = [] # store inputs that don't fit into homogeneous batches anymore\n",
    "    targets_buffer = []\n",
    "    \n",
    "    num_batches = np.ceil(len(inputs) / batch_size)\n",
    "    map_classes_buffer = build_map_classes_buffer(inputs, targets)\n",
    "    \n",
    "    for target in map_classes_buffer.keys():\n",
    "        while len(map_classes_buffer[target]) > 0:\n",
    "            taken_inputs, retrieved_inputs = map_classes_buffer[target][:batch_size], map_classes_buffer[target][batch_size:]\n",
    "            if len(taken_inputs) < batch_size:\n",
    "                inputs_buffer.extend(taken_inputs)\n",
    "                targets_buffer.extend([target for taken_input in taken_inputs])\n",
    "            else:\n",
    "                input_batches.extend(taken_inputs)\n",
    "                target_batches.extend([target for taken_input in taken_inputs])\n",
    "            map_classes_buffer[target] = retrieved_inputs\n",
    "            \n",
    "    # take missing values\n",
    "    while len(inputs_buffer) > 0:\n",
    "        taken_inputs, inputs_buffer = inputs_buffer[:batch_size], inputs_buffer[batch_size:]\n",
    "        taken_targets, targets_buffer = targets_buffer[:batch_size], targets_buffer[batch_size:]\n",
    "        input_batches.extend(taken_inputs)\n",
    "        target_batches.extend(taken_targets)\n",
    "                \n",
    "    return input_batches, target_batches\n",
    " \n",
    "sort_one_class(test_inputs, test_targets, batch_size=3, use_shuffle=False)\n",
    "assert sort_one_class(test_inputs, test_targets, batch_size=3, use_shuffle=False) == expected_output_one_class, \\\n",
    "    'Actual and expected outputs differ!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def sort_all_classes(inputs, targets, batch_size, use_shuffle=True, random_state=None):\n",
    "    '''\n",
    "    Splits the data (inputs and targets) into as many purely heterogeneous batches as possible,\n",
    "    i.e. that in as many cases as possible, the batches consist of all targets.\n",
    "    -- Params:\n",
    "    @inputs: input data for the model\n",
    "    @targets: desired outcome for the model given that it gets @inputs\n",
    "    @batch_size: number of samples per batch\n",
    "    @use_shuffle: shuffle the data beforehand\n",
    "    -- Return: one 2d list for the inputs, one 2d list for the targets\n",
    "    '''\n",
    "    \n",
    "    def try_pop(buffer):\n",
    "        try:\n",
    "            return buffer.pop()\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    \n",
    "    assert len(inputs) == len(targets), 'Inputs and targets do not have the same size'\n",
    "    \n",
    "    if use_shuffle:\n",
    "        inputs, targets = shuffle(inputs, targets, random_state=random_state)\n",
    "    \n",
    "    input_batches = []\n",
    "    target_batches = []\n",
    "    inputs_buffer = [] # store inputs that don't fit into purely heterogeneous batches anymore\n",
    "    targets_buffer = []\n",
    "    \n",
    "    num_batches = np.ceil(len(inputs) / batch_size)\n",
    "    map_classes_buffer = build_map_classes_buffer(inputs, targets)\n",
    "    \n",
    "    # check if all targets in map class buffer have at least one element\n",
    "    sorted_inputs = []\n",
    "    sorted_targets = []\n",
    "    copy_map_classes_buffer = deepcopy(map_classes_buffer)\n",
    "    while any(list(map(lambda x: len(map_classes_buffer[x]) > 0, map_classes_buffer))):\n",
    "        taken_targets = list(map(lambda x: x if try_pop(copy_map_classes_buffer[x]) is not None else None,\\\n",
    "                                 copy_map_classes_buffer)) # get one 'column'\n",
    "        taken_inputs = list(map(lambda x: try_pop(map_classes_buffer[x]), map_classes_buffer)) # get one 'column'\n",
    "        sorted_inputs.extend(taken_inputs)\n",
    "        sorted_targets.extend(taken_targets)\n",
    "        \n",
    "    sorted_inputs = [val for val in sorted_inputs if val is not None] # None vals due to try_pop workaround\n",
    "    sorted_targets = [val for val in sorted_targets if val is not None]\n",
    "    while len(sorted_inputs) > batch_size:\n",
    "        input_batches.extend(sorted_inputs[:batch_size])\n",
    "        target_batches.extend(sorted_targets[:batch_size])\n",
    "        sorted_inputs, sorted_targets = sorted_inputs[batch_size:], sorted_targets[batch_size:]\n",
    "        \n",
    "    if len(sorted_inputs) > 0: # if there are any values left\n",
    "        input_batches.extend(sorted_inputs)\n",
    "        target_batches.extend(sorted_targets)\n",
    "                \n",
    "    return input_batches, target_batches \n",
    "\n",
    "sort_all_classes(test_inputs, test_targets, batch_size=3, use_shuffle=False)\n",
    "assert sort_all_classes(test_inputs, test_targets, batch_size=3, use_shuffle=False) == expected_output_all_classes, \\\n",
    "    'Actual and expected outputs differ!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['c', 'h', 'f'], [0, 1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "def weighted_random_sampling(inputs, targets, weighted_indices, batch_size=3):\n",
    "    '''\n",
    "    In weighted random sampling (WRS) the items are weighted and the probability of \n",
    "    each item to be selected is determined by its relative weight.\n",
    "    -- Params:\n",
    "    @inputs: input data for the model\n",
    "    @targets: desired outcome for the model given that it gets @inputs\n",
    "    @weighted_indices: dictionary containing which index of the samples has which probability\n",
    "    @batch_size: number of samples per batch\n",
    "    -- Return: one batch of the inputs, one batch of the targets\n",
    "    '''\n",
    "    eps = 0.0000001 # small threshold to accept rounding errors when comparing float values\n",
    "    \n",
    "    assert len(inputs) == len(targets), 'The number of inputs to pull from must fit the number of targets'\n",
    "    assert len(inputs) == len(weighted_indices), 'The number of inputs to pull from must fit the given weighted indices'\n",
    "    assert type(weighted_indices) == dict, 'The weighted indices must be given as a dictionary'\n",
    "    assert sum(weighted_indices.values()) < 1 + eps and sum(weighted_indices.values()) > 1 - eps, \\\n",
    "        'The sum of the values for the input must add up to 1.'\n",
    "    \n",
    "    pulled_samples = []\n",
    "    pulled_targets = []\n",
    "    for _ in range(batch_size):\n",
    "        # calculate the weights of an element to be pulled\n",
    "        # must be recalculated each round, as the values have to add up to 1\n",
    "        pulled_index = np.random.choice(list(weighted_indices.keys()), p = list(weighted_indices.values()))\n",
    "        weighted_indices[pulled_index] = 0\n",
    "        sum_of_values = sum(weighted_indices.values())\n",
    "        for index, weight in weighted_indices.items():\n",
    "            weighted_indices[index] = weight / sum_of_values\n",
    "        pulled_samples.append(inputs[pulled_index])\n",
    "        pulled_targets.append(targets[pulled_index])\n",
    "    return pulled_samples, pulled_targets\n",
    "    \n",
    "    \n",
    "inputs = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'] # will be tensors\n",
    "targets = [0, 0, 0, 1, 1, 0, 1, 1]\n",
    "weighted_indices = {\n",
    "    0: 0.3,\n",
    "    1: 0.05,\n",
    "    2: 0.2,\n",
    "    3: 0.05,\n",
    "    4: 0.05,\n",
    "    5: 0.15,\n",
    "    6: 0.05,\n",
    "    7: 0.15\n",
    "}\n",
    "\n",
    "weighted_random_sampling(inputs, targets, weighted_indices, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['a', 'c', 'f'], [0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "def weighted_highest_sampling(inputs, targets, weighted_indices, batch_size=3):\n",
    "    '''\n",
    "    In weighted random sampling (WRS) the items are weighted and the probability of \n",
    "    each item to be selected is determined by its relative weight.\n",
    "    -- Params:\n",
    "    @inputs: input data for the model\n",
    "    @targets: desired outcome for the model given that it gets @inputs\n",
    "    @weighted_indices: dictionary containing which index of the samples has which probability\n",
    "    @batch_size: number of samples per batch\n",
    "    -- Return: one batch of the inputs, one batch of the targets\n",
    "    '''\n",
    "    \n",
    "    assert len(inputs) == len(targets), 'The number of inputs to pull from must fit the number of targets'\n",
    "    assert len(inputs) == len(weighted_indices), 'The number of inputs to pull from must fit the given weighted indices'\n",
    "    assert type(weighted_indices) == dict, 'The weighted indices must be given as a dictionary'\n",
    "      \n",
    "    pulled_samples = []\n",
    "    pulled_targets = []\n",
    "    for _ in range(batch_size):\n",
    "        pulled_index = max(weighted_indices.items(), key=operator.itemgetter(1))[0]\n",
    "        weighted_indices[pulled_index] = 0\n",
    "        pulled_samples.append(inputs[pulled_index])\n",
    "        pulled_targets.append(targets[pulled_index])\n",
    "    return pulled_samples, pulled_targets\n",
    "    \n",
    "    \n",
    "inputs = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'] # will be tensors\n",
    "targets = [0, 0, 0, 1, 1, 0, 1, 1]\n",
    "weighted_indices = {\n",
    "    0: 0.3,\n",
    "    1: 0.05,\n",
    "    2: 0.2,\n",
    "    3: 0.05,\n",
    "    4: 0.05,\n",
    "    5: 0.15,\n",
    "    6: 0.05,\n",
    "    7: 0.15\n",
    "}\n",
    "\n",
    "weighted_highest_sampling(inputs, targets, weighted_indices, batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "batch_size = 64\n",
    "# prepare test data\n",
    "X = np.random.rand(num_samples, 32, 32)\n",
    "Y = np.random.randint(10, size=num_samples)\n",
    "weighted_indices = {index: abs(np.random.normal(loc=0, scale=1)) for index in range(len(X))}\n",
    "sum_indices = sum(weighted_indices.values())\n",
    "for key, value in weighted_indices.items():\n",
    "    weighted_indices[key] /= sum_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy, Y_copy, wi_copy = X.copy(), Y.copy(), weighted_indices.copy()\n",
    "start = timeit.default_timer()\n",
    "_ = shuffle(X_copy, Y_copy)\n",
    "stop = timeit.default_timer()\n",
    "times['shuffle'] = stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy, Y_copy, wi_copy = X.copy(), Y.copy(), weighted_indices.copy()\n",
    "start = timeit.default_timer()\n",
    "_ = weighted_highest_sampling(X_copy, Y_copy, wi_copy,  batch_size=batch_size)\n",
    "stop = timeit.default_timer()\n",
    "times['whs'] = stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy, Y_copy, wi_copy = X.copy(), Y.copy(), weighted_indices.copy()\n",
    "start = timeit.default_timer()\n",
    "_ = weighted_random_sampling(X_copy, Y_copy, wi_copy,  batch_size=batch_size)\n",
    "stop = timeit.default_timer()\n",
    "times['wrs'] = stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy, Y_copy, wi_copy = X.copy(), Y.copy(), weighted_indices.copy()\n",
    "start = timeit.default_timer()\n",
    "_ = sort_one_class(X_copy, Y_copy, batch_size)\n",
    "stop = timeit.default_timer()\n",
    "times['homogeneous'] = stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy, Y_copy, wi_copy = X.copy(), Y.copy(), weighted_indices.copy()\n",
    "start = timeit.default_timer()\n",
    "_ = sort_all_classes(X_copy, Y_copy, batch_size)\n",
    "stop = timeit.default_timer()\n",
    "times['heterogeneous'] = stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(times.keys(), times.values())\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel('seconds needed')\n",
    "plt.title('Batching for {} samples'.format(num_samples))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
