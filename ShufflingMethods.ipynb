{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = ['abc', 'def', 'egh', 'ijk', 'lmn', 'opq', 'rst', 'ade', 'des', 'asd', 'a', 'sd', 'sda', 'e']\n",
    "test_targets = [1, 2, 1, 1, 2, 1, 2, 3, 4, 3, 1, 4, 2, 3]\n",
    "\n",
    "expected_output_one_class = [\n",
    "    ['abc', 'egh', 'ijk'],\n",
    "    ['def', 'lmn', 'rst'],\n",
    "    ['ade', 'asd', 'e'],\n",
    "    ['opq', 'a', 'sda'],\n",
    "    ['des', 'sd']\n",
    "]\n",
    "\n",
    "expected_output_all_classes = [\n",
    "    ['a', 'sda', 'e'],\n",
    "    ['sd', 'opq', 'rst'],\n",
    "    ['asd', 'des', 'ijk'],\n",
    "    ['lmn', 'ade', 'egh'],\n",
    "    ['def', 'abc']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_map_classes_buffer(inputs, targets):\n",
    "    '''\n",
    "    Build a dictionary which has the targets as keys and all the corresponding inputs as values\n",
    "    -- Params:\n",
    "    @inputs: input data for the model\n",
    "    @targets: desired outcome for the model given that it gets @inputs\n",
    "    -- Return: dictionary\n",
    "    '''\n",
    "    # build a dictionary to grab pairs from\n",
    "    map_classes_buffer = defaultdict(list) # stores class -> inputs pairs\n",
    "    list(map(lambda x, y: map_classes_buffer[y].append(x), inputs, targets)) #without list, the writes to the map are not commited\n",
    "    return map_classes_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def batches_one_class(inputs, targets, batch_size=64):\n",
    "    '''\n",
    "    Splits the data (inputs and targets) into as many homogeneous batches as possible,\n",
    "    i.e. that in as many cases as possible, the batches consist of one target only.\n",
    "    -- Params:\n",
    "    @inputs: input data for the model\n",
    "    @targets: desired outcome for the model given that it gets @inputs\n",
    "    @batch_size: number of samples per batch\n",
    "    -- Return: 2d list\n",
    "    '''\n",
    "    \n",
    "    assert len(inputs) == len(targets), 'Inputs and targets do not have the same size'\n",
    "    \n",
    "    batches = []\n",
    "    inputs_buffer = [] # store inputs that don't fit into homogeneous batches anymore\n",
    "    \n",
    "    num_batches = np.ceil(len(inputs) / batch_size)\n",
    "    map_classes_buffer = build_map_classes_buffer(inputs, targets)\n",
    "    \n",
    "    for target in map_classes_buffer.keys():\n",
    "        while len(map_classes_buffer[target]) > 0:\n",
    "            taken_inputs, retrieved_inputs = map_classes_buffer[target][:batch_size], map_classes_buffer[target][batch_size:]\n",
    "            if len(taken_inputs) < batch_size:\n",
    "                inputs_buffer.extend(taken_inputs)\n",
    "            else:\n",
    "                batches.append(taken_inputs)\n",
    "            map_classes_buffer[target] = retrieved_inputs\n",
    "            \n",
    "    # take missing values\n",
    "    while len(inputs_buffer) > 0:\n",
    "        taken_inputs, inputs_buffer = inputs_buffer[:batch_size], inputs_buffer[batch_size:]\n",
    "        batches.append(taken_inputs)\n",
    "                \n",
    "    assert len(batches) == num_batches, 'Error in implementation, number of batches is wrong!'\n",
    "    \n",
    "    return batches\n",
    "    \n",
    "    \n",
    "assert batches_one_class(test_inputs, test_targets, batch_size=3) == expected_output_one_class, \\\n",
    "    'Actual and expected outputs differ!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches_all_classes(inputs, targets, batch_size=64):\n",
    "    '''\n",
    "    Splits the data (inputs and targets) into as many purely heterogeneous batches as possible,\n",
    "    i.e. that in as many cases as possible, the batches consist of all targets.\n",
    "    -- Params:\n",
    "    @inputs: input data for the model\n",
    "    @targets: desired outcome for the model given that it gets @inputs\n",
    "    @batch_size: number of samples per batch\n",
    "    -- Return: 2d list\n",
    "    '''\n",
    "    \n",
    "    def try_pop(buffer):\n",
    "        try:\n",
    "            return buffer.pop()\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    \n",
    "    assert len(inputs) == len(targets), 'Inputs and targets do not have the same size'\n",
    "    \n",
    "    batches = []\n",
    "    inputs_buffer = [] # store inputs that don't fit into purely heterogeneous batches anymore\n",
    "    \n",
    "    num_batches = np.ceil(len(inputs) / batch_size)\n",
    "    map_classes_buffer = build_map_classes_buffer(inputs, targets)\n",
    "    \n",
    "    # check if all targets in map class buffer have at least one element\n",
    "    sorted_by_targets = []\n",
    "    while any(list(map(lambda x: len(map_classes_buffer[x]) > 0, map_classes_buffer))):\n",
    "        taken_inputs = list(map(lambda x: try_pop(map_classes_buffer[x]), map_classes_buffer)) # get one 'column'\n",
    "        sorted_by_targets.extend(taken_inputs)\n",
    "        \n",
    "    sorted_by_targets = [val for val in sorted_by_targets if val is not None] # None vals due to try_pop workaround\n",
    "    while len(sorted_by_targets) > batch_size:\n",
    "        batches.append(sorted_by_targets[:batch_size])\n",
    "        sorted_by_targets = sorted_by_targets[batch_size:]\n",
    "        \n",
    "    if len(sorted_by_targets) > 0: # if there are any values left\n",
    "        batches.append(sorted_by_targets)\n",
    "            \n",
    "    assert len(batches) == num_batches, 'Error in implementation, number of batches is wrong!'\n",
    "    \n",
    "    return batches \n",
    "\n",
    "assert batches_all_classes(test_inputs, test_targets, batch_size=3) == expected_output_all_classes, \\\n",
    "    'Actual and expected outputs differ!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from utils.data_utils import DataLoader\n",
    "dataloader = DataLoader(batch_sizes={'train': 64, 'test': 64}, shuffle={'train': False, 'test': False})\n",
    "dataloader.download_cifar()\n",
    "trainloader, testloader = dataloader.get_loaders()\n",
    "\n",
    "for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "    _inputs = inputs\n",
    "    _targets = targets\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
